{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install -q datasets\n",
    "!pip install -q opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import gc\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코랩 환경 확인 및 GPU 설정\n",
    "\n",
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "    print(f\"GPU 모델: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# 메모리 확보를 위해 사용 가능한 CUDA 캐시 지우기\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# CUDA 메모리 정보 출력 함수\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'할당된 GPU 메모리: {torch.cuda.memory_allocated() / 1e9:.2f} GB')\n",
    "        print(f'캐시된 GPU 메모리: {torch.cuda.memory_reserved() / 1e9:.2f} GB')\n",
    "        print(f'최대 할당된 GPU 메모리: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB')\n",
    "\n",
    "\n",
    "\n",
    "# 메모리 최적화 설정 (메모리 사용량 절약)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "\n",
    "# 뇌종양 데이터셋 클래스 정의\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, dataset_split, transform=None, mask_transform=None):\n",
    "        self.dataset = dataset_split\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        # 이미지 가져오기\n",
    "        image = item['image']\n",
    "        \n",
    "        # 세그멘테이션 마스크 생성\n",
    "        mask = np.zeros((item['height'], item['width']), dtype=np.uint8)\n",
    "        if len(item['segmentation']) > 0 and item['category_id'] == 1:  # 종양이 있는 경우\n",
    "            # 세그멘테이션 데이터를 마스크로 변환\n",
    "            for polygon in item['segmentation']:\n",
    "                # polygon은 [x1, y1, x2, y2, ...] 형태의 좌표 리스트\n",
    "                poly_array = np.array(polygon).reshape(-1, 2)\n",
    "                # fillPoly로 마스크 채우기\n",
    "                cv2.fillPoly(mask, [poly_array.astype(np.int32)], 1)\n",
    "        \n",
    "        # PIL 이미지로 변환\n",
    "        image_pil = Image.fromarray(np.array(image))\n",
    "        mask_pil = Image.fromarray(mask * 255)  # 0-1 마스크를 0-255로 변환\n",
    "        \n",
    "        # 변환 적용\n",
    "        if self.transform is not None:\n",
    "            image_pil = self.transform(image_pil)\n",
    "        \n",
    "        if self.mask_transform is not None:\n",
    "            mask_pil = self.mask_transform(mask_pil)\n",
    "        \n",
    "        return image_pil, mask_pil\n",
    "\n",
    "# 메모리 효율적인 BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or inplanes != planes * self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or inplanes != planes * self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 메모리 효율적인 HRNet 정의 - 더 작은 크기로 조정\n",
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels, num_channels, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.num_branches = num_branches\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "        \n",
    "        self.branches = self._make_branches(num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.num_inchannels[branch_index], num_channels[branch_index], stride))\n",
    "        \n",
    "        self.num_inchannels[branch_index] = num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(block(self.num_inchannels[branch_index], num_channels[branch_index]))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "        for i in range(num_branches):\n",
    "            branches.append(self._make_one_branch(i, block, num_blocks, num_channels))\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "        \n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        \n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    # 업샘플링\n",
    "                    fuse_layer.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_inchannels[j], num_inchannels[i], kernel_size=1, bias=False),\n",
    "                        nn.BatchNorm2d(num_inchannels[i]),\n",
    "                        nn.Upsample(scale_factor=2**(j-i), mode='nearest')\n",
    "                    ))\n",
    "                elif j == i:\n",
    "                    # 같은 해상도\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    # 다운샘플링\n",
    "                    ops = []\n",
    "                    for k in range(i - j):\n",
    "                        if k == i - j - 1:\n",
    "                            ops.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j], num_inchannels[i], kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                                nn.BatchNorm2d(num_inchannels[i])\n",
    "                            ))\n",
    "                        else:\n",
    "                            ops.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j], num_inchannels[j], kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                                nn.BatchNorm2d(num_inchannels[j]),\n",
    "                                nn.ReLU(inplace=True)\n",
    "                            ))\n",
    "                    fuse_layer.append(nn.Sequential(*ops))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "        \n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "        \n",
    "        if self.fuse_layers is not None:\n",
    "            y = []\n",
    "            for i in range(len(self.fuse_layers)):\n",
    "                y_branch = x[0] if self.fuse_layers[i][0] is None else self.fuse_layers[i][0](x[0])\n",
    "                for j in range(1, self.num_branches):\n",
    "                    if self.fuse_layers[i][j] is not None:\n",
    "                        y_branch = y_branch + self.fuse_layers[i][j](x[j])\n",
    "                y.append(self.relu(y_branch))\n",
    "            \n",
    "            return y\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "# 메모리 효율적인 HRNetV2 - 작은 크기의 모델\n",
    "class HRNetV2_Small(nn.Module):\n",
    "    def __init__(self, num_classes=2):  # 배경 + 종양\n",
    "        super(HRNetV2_Small, self).__init__()\n",
    "        # 스템 네트워크 - 더 작은 채널 사용\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 스테이지 1 - 더 작은 채널 수\n",
    "        self.stage1_branch1 = self._make_layer(Bottleneck, 32, 32, 2)  # 블록 수 줄임\n",
    "        self.transition1 = self._make_transition_layer([128], [16, 32])  # 채널 수 줄임\n",
    "        \n",
    "        # 스테이지 2 - 더 작은 채널 수, 블록 수 줄임\n",
    "        self.stage2_branches = HighResolutionModule(\n",
    "            num_branches=2,\n",
    "            blocks=BasicBlock,\n",
    "            num_blocks=[2, 2],  # 블록 수 줄임\n",
    "            num_inchannels=[16, 32],  # 채널 수 줄임\n",
    "            num_channels=[16, 32]  # 채널 수 줄임\n",
    "        )\n",
    "        \n",
    "        # 스테이지 3 - 더 작은 채널 수, 블록 수 줄임\n",
    "        self.transition2 = self._make_transition_layer([16, 32], [16, 32, 64])  # 채널 수 줄임\n",
    "        self.stage3_branches = HighResolutionModule(\n",
    "            num_branches=3,\n",
    "            blocks=BasicBlock,\n",
    "            num_blocks=[2, 2, 2],  # 블록 수 줄임\n",
    "            num_inchannels=[16, 32, 64],  # 채널 수 줄임\n",
    "            num_channels=[16, 32, 64]  # 채널 수 줄임\n",
    "        )\n",
    "        \n",
    "        # 스테이지 4 - 더 작은 채널 수, 블록 수 줄임\n",
    "        self.transition3 = self._make_transition_layer([16, 32, 64], [16, 32, 64, 128])  # 채널 수 줄임\n",
    "        self.stage4_branches = HighResolutionModule(\n",
    "            num_branches=4,\n",
    "            blocks=BasicBlock,\n",
    "            num_blocks=[2, 2, 2, 2],  # 블록 수 줄임\n",
    "            num_inchannels=[16, 32, 64, 128],  # 채널 수 줄임\n",
    "            num_channels=[16, 32, 64, 128]  # 채널 수 줄임\n",
    "        )\n",
    "        \n",
    "        # 세그멘테이션 헤드\n",
    "        self.head_channels = [16, 32, 64, 128]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(sum(self.head_channels), 128, kernel_size=1, stride=1, padding=0),  # 더 작은 채널 사용\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, num_classes, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "        \n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_transition_layer(self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "        \n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                # 채널 수 조정\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i], num_channels_cur_layer[i], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(num_channels_cur_layer[i]),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    ))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                # 해상도 감소 및 채널 수 조정\n",
    "                conv_downsamples = []\n",
    "                for j in range(i - num_branches_pre + 1):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] if j == i - num_branches_pre else inchannels\n",
    "                    conv_downsamples.append(nn.Sequential(\n",
    "                        nn.Conv2d(inchannels, outchannels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannels),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    ))\n",
    "                transition_layers.append(nn.Sequential(*conv_downsamples))\n",
    "        \n",
    "        return nn.ModuleList(transition_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 스템 네트워크\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # 스테이지 1\n",
    "        x = self.stage1_branch1(x)\n",
    "        \n",
    "        # 스테이지 2\n",
    "        x_list = []\n",
    "        for i, trans in enumerate(self.transition1):\n",
    "            if trans is None:\n",
    "                x_list.append(x)\n",
    "            else:\n",
    "                x_list.append(trans(x))\n",
    "        y_list = self.stage2_branches(x_list)\n",
    "        \n",
    "        # 스테이지 3\n",
    "        x_list = []\n",
    "        for i, trans in enumerate(self.transition2):\n",
    "            if trans is None:\n",
    "                x_list.append(y_list[i])\n",
    "            else:\n",
    "                x_list.append(trans(y_list[-1]))\n",
    "        y_list = self.stage3_branches(x_list)\n",
    "        \n",
    "        # 스테이지 4\n",
    "        x_list = []\n",
    "        for i, trans in enumerate(self.transition3):\n",
    "            if trans is None:\n",
    "                x_list.append(y_list[i])\n",
    "            else:\n",
    "                x_list.append(trans(y_list[-1]))\n",
    "        y_list = self.stage4_branches(x_list)\n",
    "        \n",
    "        # 세그멘테이션 헤드를 위한 특징 맵 융합\n",
    "        y = torch.cat([\n",
    "            F.interpolate(y_list[0], size=y_list[0].size()[2:], mode='bilinear', align_corners=True),\n",
    "            F.interpolate(y_list[1], size=y_list[0].size()[2:], mode='bilinear', align_corners=True),\n",
    "            F.interpolate(y_list[2], size=y_list[0].size()[2:], mode='bilinear', align_corners=True),\n",
    "            F.interpolate(y_list[3], size=y_list[0].size()[2:], mode='bilinear', align_corners=True)\n",
    "        ], dim=1)\n",
    "        \n",
    "        # 세그멘테이션 헤드\n",
    "        y = self.head(y)\n",
    "        \n",
    "        # 원본 이미지 크기로 업샘플링\n",
    "        y = F.interpolate(y, scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return y\n",
    "\n",
    "# 데이터 전처리 및 로더 생성 함수 - 더 작은 이미지 크기 및 배치 크기 사용\n",
    "def get_data_loaders(batch_size=4, val_split=0.2, num_workers=2, img_size=256):\n",
    "    # 데이터셋 로드\n",
    "    print(\"데이터셋 로드 중...\")\n",
    "    dataset = load_dataset(\"dwb2023/brain-tumor-image-dataset-semantic-segmentation\")\n",
    "    \n",
    "    # 학습/검증 분할\n",
    "    train_dataset = dataset['train']\n",
    "    \n",
    "    # 데이터 변환 - 더 작은 이미지 크기\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # 데이터셋 객체 생성\n",
    "    print(\"데이터셋 분할 중...\")\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(train_dataset)), \n",
    "        test_size=val_split, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"학습 데이터 크기: {len(train_indices)}, 검증 데이터 크기: {len(val_indices)}\")\n",
    "    \n",
    "    train_subset = [train_dataset[i] for i in train_indices]\n",
    "    val_subset = [train_dataset[i] for i in val_indices]\n",
    "    \n",
    "    train_dataset_obj = BrainTumorDataset(train_subset, transform, mask_transform)\n",
    "    val_dataset_obj = BrainTumorDataset(val_subset, transform, mask_transform)\n",
    "    \n",
    "    # 데이터 로더 생성 - 더 작은 배치 크기와 num_workers\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset_obj, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_obj, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# 손실 함수 정의\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: [B, C, H, W], targets: [B, 1, H, W]\n",
    "        # 소프트맥스 적용\n",
    "        inputs = F.softmax(inputs, dim=1)\n",
    "        \n",
    "        # 종양 클래스에 대한 예측만 추출 (인덱스 1)\n",
    "        inputs = inputs[:, 1:2, :, :]\n",
    "        \n",
    "        # 평활화 - view 대신 reshape 사용\n",
    "        inputs = inputs.reshape(-1)\n",
    "        targets = targets.reshape(-1)\n",
    "        \n",
    "        # 다이스 계수 계산\n",
    "        intersection = (inputs * targets).sum()\n",
    "        union = inputs.sum() + targets.sum()\n",
    "        \n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "# 학습 함수 - 메모리 최적화\n",
    "def train_model(model, train_loader, val_loader, num_epochs=50, lr=1e-3, device='cuda', save_dir='./models'):\n",
    "    # 모델 저장 디렉토리 생성\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = DiceLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # 그래디언트 스케일링으로 mixed precision 훈련 설정\n",
    "    scaler = torch.amp.GradScaler('cuda')  # FutureWarning 수정\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # 학습 모드\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            # mixed precision 훈련 사용 (FutureWarning 수정)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "            \n",
    "            # 역전파 및 최적화 (mixed precision)\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "            # 메모리 효율성을 위한 중간 정리\n",
    "            del images, masks, outputs, loss\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # 검증 모드\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                masks = masks.to(device, non_blocking=True)\n",
    "                \n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # 메모리 효율성을 위한 중간 정리\n",
    "                del images, masks, outputs, loss\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # 현재 학습률 출력\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # 에폭 시간 계산\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Time: {epoch_time:.2f}s, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {current_lr:.6f}')\n",
    "        \n",
    "        # 모델 저장\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            model_to_save = model\n",
    "            torch.save(model_to_save.state_dict(), f'{save_dir}/hrnet_brain_tumor_best.pth')\n",
    "            print(f'Model saved with Val Loss: {best_val_loss:.4f}')\n",
    "        \n",
    "        # 마지막 에폭 모델도 저장\n",
    "        if epoch == num_epochs - 1:\n",
    "            model_to_save = model\n",
    "            torch.save(model_to_save.state_dict(), f'{save_dir}/hrnet_brain_tumor_last.pth')\n",
    "            \n",
    "        # 메모리 사용량 출력\n",
    "        print_gpu_memory()\n",
    "        \n",
    "        # 가비지 컬렉션 강제 수행\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # 학습 진행 그래프 그리기\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{save_dir}/training_curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# 평가 지표 계산 함수\n",
    "def calculate_metrics(model, data_loader, device='cuda', threshold=0.5):\n",
    "    \"\"\"\n",
    "    모델 성능을 평가하는 다양한 지표를 계산합니다.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_score = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(data_loader, desc=\"평가 중\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            masks = masks.to(device, non_blocking=True)\n",
    "            \n",
    "            # 모델 예측\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "            \n",
    "            # 소프트맥스 적용 (클래스가 2개 이상인 경우)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # 종양 클래스에 대한 확률 (보통 인덱스 1)\n",
    "            tumor_prob = probs[:, 1, :, :]\n",
    "            \n",
    "            # 예측 마스크 (임계값 적용)\n",
    "            pred_masks = (tumor_prob > threshold).float()\n",
    "            \n",
    "            # 배치의 모든 이미지에 대해 true와 pred 값 수집\n",
    "            for i in range(masks.size(0)):\n",
    "                # CPU로 이동하고 넘파이 배열로 변환\n",
    "                true_mask_np = masks[i].squeeze().cpu().numpy().flatten()\n",
    "                pred_mask_np = pred_masks[i].cpu().numpy().flatten()\n",
    "                tumor_prob_np = tumor_prob[i].cpu().numpy().flatten()\n",
    "                \n",
    "                y_true.append(true_mask_np)\n",
    "                y_pred.append(pred_mask_np)\n",
    "                y_score.append(tumor_prob_np)\n",
    "            \n",
    "            # 메모리 관리를 위해 텐서 해제\n",
    "            del images, masks, outputs, probs, tumor_prob, pred_masks\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # 모든 배치의 결과를 하나의 배열로 연결\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_score = np.concatenate(y_score)\n",
    "    \n",
    "    # F1 점수 계산\n",
    "    from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "    f1 = f1_score(y_true > 0.5, y_pred > 0.5)\n",
    "    \n",
    "    # ROC-AUC 계산\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_score)\n",
    "    except:\n",
    "        roc_auc = 0.0\n",
    "        print(\"ROC-AUC 계산 중 오류가 발생했습니다. 일반적으로 클래스가 하나만 존재할 때 발생합니다.\")\n",
    "    \n",
    "    # IoU (Jaccard 인덱스) 계산\n",
    "    intersection = np.logical_and(y_true > 0.5, y_pred > 0.5).sum()\n",
    "    union = np.logical_or(y_true > 0.5, y_pred > 0.5).sum()\n",
    "    iou_score = intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    # Dice 점수 계산\n",
    "    dice_score = 2 * intersection / (np.sum(y_true > 0.5) + np.sum(y_pred > 0.5)) if (np.sum(y_true > 0.5) + np.sum(y_pred > 0.5)) > 0 else 0.0\n",
    "    \n",
    "    # 혼동 행렬 계산\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true > 0.5, y_pred > 0.5).ravel()\n",
    "    \n",
    "    # 정밀도, 재현율 계산\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    # 결과 반환\n",
    "    metrics = {\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'iou_score': iou_score,\n",
    "        'dice_score': dice_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'true_negatives': tn,\n",
    "        'false_negatives': fn\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def visualize_results(model, data_loader, num_samples=5, device='cuda', threshold=0.5, save_dir='./results'):\n",
    "    \"\"\"\n",
    "    모델의 세그멘테이션 결과를 시각화합니다.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.eval()\n",
    "    \n",
    "    # 시각화를 위한 샘플 가져오기\n",
    "    images_list = []\n",
    "    masks_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in data_loader:\n",
    "            if len(images_list) >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = images.to(device, non_blocking=True)\n",
    "            \n",
    "            # 모델 예측\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(images)\n",
    "            \n",
    "            # 소프트맥스 적용 (클래스가 2개 이상인 경우)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # 종양 클래스에 대한 확률 (보통 인덱스 1)\n",
    "            tumor_prob = probs[:, 1, :, :]\n",
    "            \n",
    "            # 예측 마스크 (임계값 적용)\n",
    "            pred_masks = (tumor_prob > threshold).float()\n",
    "            \n",
    "            # CPU로 이동\n",
    "            images_cpu = images.cpu()\n",
    "            masks_cpu = masks.cpu()\n",
    "            preds_cpu = pred_masks.cpu()\n",
    "            \n",
    "            # 각 배치의 이미지 추가\n",
    "            for i in range(min(images.size(0), num_samples - len(images_list))):\n",
    "                images_list.append(images_cpu[i])\n",
    "                masks_list.append(masks_cpu[i])\n",
    "                preds_list.append(preds_cpu[i])\n",
    "            \n",
    "            # 메모리 관리\n",
    "            del images, masks, outputs, probs, tumor_prob, pred_masks\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # 결과 시각화\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 원본 이미지\n",
    "        img = images_list[i].permute(1, 2, 0).numpy()\n",
    "        # 정규화 복원 (ImageNet 평균, 표준편차 사용 가정)\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # 실제 마스크\n",
    "        mask = masks_list[i].squeeze().numpy()\n",
    "        \n",
    "        # 예측 마스크\n",
    "        pred = preds_list[i].squeeze().numpy()\n",
    "        \n",
    "        # 그리기\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title('원본 이미지')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(mask, cmap='gray')\n",
    "        axes[i, 1].set_title('실제 마스크')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(pred, cmap='gray')\n",
    "        axes[i, 2].set_title('예측 마스크')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/segmentation_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 메모리 관리\n",
    "    plt.close(fig)\n",
    "    del images_list, masks_list, preds_list\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda', save_dir='./results'):\n",
    "    \"\"\"\n",
    "    모델을 평가하고 모든 지표를 출력합니다.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print(\"모델 평가 중...\")\n",
    "    \n",
    "    # 성능 지표 계산\n",
    "    metrics = calculate_metrics(model, test_loader, device)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\n=== 모델 평가 결과 ===\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"IoU Score: {metrics['iou_score']:.4f}\")\n",
    "    print(f\"Dice Score: {metrics['dice_score']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(\"\\n=== 혼동 행렬 ===\")\n",
    "    print(f\"True Positives: {metrics['true_positives']}\")\n",
    "    print(f\"False Positives: {metrics['false_positives']}\")\n",
    "    print(f\"True Negatives: {metrics['true_negatives']}\")\n",
    "    print(f\"False Negatives: {metrics['false_negatives']}\")\n",
    "    \n",
    "    # 결과 시각화\n",
    "    print(\"\\n결과 시각화 중...\")\n",
    "    visualize_results(model, test_loader, num_samples=5, device=device, save_dir=save_dir)\n",
    "    \n",
    "    # 결과 저장\n",
    "    with open(f'{save_dir}/evaluation_results.txt', 'w') as f:\n",
    "        f.write(\"=== 모델 평가 결과 ===\\n\")\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "    # GPU 설정\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"사용 장치: {device}\")\n",
    "    \n",
    "    # 하이퍼파라미터 설정 - 메모리 제한에 맞게 최적화\n",
    "    batch_size = 2  # 매우 작은 배치 크기\n",
    "    num_workers = 2  # 작은 worker 수\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 30\n",
    "    img_size = 256  # 매우 작은 이미지 크기\n",
    "    \n",
    "    # 데이터 로더 생성\n",
    "    train_loader, val_loader = get_data_loaders(\n",
    "        batch_size=batch_size, \n",
    "        num_workers=num_workers,\n",
    "        img_size=img_size\n",
    "    )\n",
    "    \n",
    "    # 메모리 사용량 초기 출력\n",
    "    print(\"\\n초기 GPU 메모리 상태:\")\n",
    "    print_gpu_memory()\n",
    "    \n",
    "    # 모델 생성 - 작은 모델 사용\n",
    "    print(\"\\n모델 생성 중...\")\n",
    "    model = HRNetV2_Small(num_classes=2)\n",
    "    print(f\"모델 생성 완료 - 파라미터 수: {sum(p.numel() for p in model.parameters())/1_000_000:.2f}M\")\n",
    "    \n",
    "    # 모델 디버깅 정보 출력 (선택사항)\n",
    "    print(\"메모리 상태 확인:\")\n",
    "    print_gpu_memory()\n",
    "    \n",
    "    # 학습 실행\n",
    "    print(\"\\n학습 시작...\")\n",
    "    train_losses, val_losses = train_model(\n",
    "        model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        num_epochs=num_epochs, \n",
    "        lr=learning_rate,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # 최고 성능 모델 로드\n",
    "    best_model = HRNetV2_Small(num_classes=2)\n",
    "    best_model.load_state_dict(torch.load('./models/hrnet_brain_tumor_best.pth'))\n",
    "    best_model = best_model.to(device)\n",
    "    \n",
    "    # 평가\n",
    "    evaluate_model(best_model, val_loader, device=device)\n",
    "    \n",
    "    print(\"학습 및 평가 완료!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # GPU 캐시 초기화\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # 메인 함수 실행\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
