{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e68c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.0-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.22.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached numpy-2.2.5-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached torch-2.7.0-cp312-cp312-win_amd64.whl (212.5 MB)\n",
      "Using cached torchvision-0.22.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Downloading torchaudio-2.7.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.4/2.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 11.0 MB/s eta 0:00:00\n",
      "Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-2.2.5-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached setuptools-80.0.1-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, setuptools, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----------------------------------------  0/14 [mpmath]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   ----- ----------------------------------  2/14 [sympy]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   -------- -------------------------------  3/14 [setuptools]\n",
      "   ----------- ----------------------------  4/14 [pillow]\n",
      "   ----------- ----------------------------  4/14 [pillow]\n",
      "   ----------- ----------------------------  4/14 [pillow]\n",
      "   ----------- ----------------------------  4/14 [pillow]\n",
      "   ----------- ----------------------------  4/14 [pillow]\n",
      "   ----------- ----------------------------  4/14 [pillow]\n",
      "   ----------- ----------------------------  4/14 [pillow]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   -------------- -------------------------  5/14 [numpy]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ----------------- ----------------------  6/14 [networkx]\n",
      "   ---------------------- -----------------  8/14 [fsspec]\n",
      "   ---------------------- -----------------  8/14 [fsspec]\n",
      "   ---------------------- -----------------  8/14 [fsspec]\n",
      "   ---------------------- -----------------  8/14 [fsspec]\n",
      "   ---------------------- -----------------  8/14 [fsspec]\n",
      "   ---------------------- -----------------  8/14 [fsspec]\n",
      "   ------------------------- --------------  9/14 [filelock]\n",
      "   ---------------------------- ----------- 10/14 [jinja2]\n",
      "   ---------------------------- ----------- 10/14 [jinja2]\n",
      "   ---------------------------- ----------- 10/14 [jinja2]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ------------------------------- -------- 11/14 [torch]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ---------------------------------- ----- 12/14 [torchvision]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ------------------------------------- -- 13/14 [torchaudio]\n",
      "   ---------------------------------------- 14/14 [torchaudio]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.5 pillow-11.2.1 setuptools-80.0.1 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 typing-extensions-4.13.2\n",
      "Requirement already satisfied: numpy in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (2.2.5)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.57.0-cp312-cp312-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.1-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Using cached contourpy-1.3.2-cp312-cp312-win_amd64.whl (223 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.57.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tqdm, threadpoolctl, scipy, pyparsing, opencv-python, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib\n",
      "\n",
      "   ----------------------------------------  0/12 [tqdm]\n",
      "   ----------------------------------------  0/12 [tqdm]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ------ ---------------------------------  2/12 [scipy]\n",
      "   ---------- -----------------------------  3/12 [pyparsing]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   -------------------- -------------------  6/12 [joblib]\n",
      "   -------------------- -------------------  6/12 [joblib]\n",
      "   -------------------- -------------------  6/12 [joblib]\n",
      "   -------------------- -------------------  6/12 [joblib]\n",
      "   -------------------- -------------------  6/12 [joblib]\n",
      "   -------------------- -------------------  6/12 [joblib]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ----------------------- ----------------  7/12 [fonttools]\n",
      "   ------------------------------ ---------  9/12 [contourpy]\n",
      "   ------------------------------ ---------  9/12 [contourpy]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   --------------------------------- ------ 10/12 [scikit-learn]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ------------------------------------ --- 11/12 [matplotlib]\n",
      "   ---------------------------------------- 12/12 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 joblib-1.4.2 kiwisolver-1.4.8 matplotlib-3.10.1 opencv-python-4.11.0.86 pyparsing-3.2.3 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0 tqdm-4.67.1\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (2.2.5)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp->datasets)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\n",
      "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
      "Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-win_amd64.whl (25.7 MB)\n",
      "   ---------------------------------------- 0.0/25.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.1/25.7 MB 13.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.7/25.7 MB 11.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/25.7 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.7/25.7 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.1/25.7 MB 11.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.4/25.7 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.0/25.7 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.4/25.7 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 21.5/25.7 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.1/25.7 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.7/25.7 MB 11.3 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, pyyaml, pyarrow, propcache, multidict, idna, fsspec, frozenlist, dill, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, pandas, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "\n",
      "   ----------------------------------------  0/24 [pytz]\n",
      "   ----------------------------------------  0/24 [pytz]\n",
      "   --- ------------------------------------  2/24 [urllib3]\n",
      "   --- ------------------------------------  2/24 [urllib3]\n",
      "   --- ------------------------------------  2/24 [urllib3]\n",
      "   ----- ----------------------------------  3/24 [tzdata]\n",
      "   ----- ----------------------------------  3/24 [tzdata]\n",
      "   ----- ----------------------------------  3/24 [tzdata]\n",
      "   ------ ---------------------------------  4/24 [pyyaml]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   -------- -------------------------------  5/24 [pyarrow]\n",
      "   ----------- ----------------------------  7/24 [multidict]\n",
      "   ------------- --------------------------  8/24 [idna]\n",
      "  Attempting uninstall: fsspec\n",
      "   ------------- --------------------------  8/24 [idna]\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "   ------------- --------------------------  8/24 [idna]\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "   ------------- --------------------------  8/24 [idna]\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "   ------------- --------------------------  8/24 [idna]\n",
      "   --------------- ------------------------  9/24 [fsspec]\n",
      "   --------------- ------------------------  9/24 [fsspec]\n",
      "   --------------- ------------------------  9/24 [fsspec]\n",
      "   --------------- ------------------------  9/24 [fsspec]\n",
      "   ------------------ --------------------- 11/24 [dill]\n",
      "   ------------------ --------------------- 11/24 [dill]\n",
      "   ------------------ --------------------- 11/24 [dill]\n",
      "   ------------------ --------------------- 11/24 [dill]\n",
      "   -------------------- ------------------- 12/24 [charset-normalizer]\n",
      "   ----------------------- ---------------- 14/24 [attrs]\n",
      "   ----------------------- ---------------- 14/24 [attrs]\n",
      "   -------------------------- ------------- 16/24 [yarl]\n",
      "   ---------------------------- ----------- 17/24 [requests]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------- -------- 19/24 [multiprocess]\n",
      "   ------------------------------- -------- 19/24 [multiprocess]\n",
      "   ------------------------------- -------- 19/24 [multiprocess]\n",
      "   ------------------------------- -------- 19/24 [multiprocess]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ------------------------------------ --- 22/24 [aiohttp]\n",
      "   ------------------------------------ --- 22/24 [aiohttp]\n",
      "   ------------------------------------ --- 22/24 [aiohttp]\n",
      "   ------------------------------------ --- 22/24 [aiohttp]\n",
      "   ------------------------------------ --- 22/24 [aiohttp]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   ---------------------------------------- 24/24 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 attrs-25.3.0 certifi-2025.4.26 charset-normalizer-3.4.1 datasets-3.5.1 dill-0.3.8 frozenlist-1.6.0 fsspec-2025.3.0 huggingface-hub-0.30.2 idna-3.10 multidict-6.4.3 multiprocess-0.70.16 pandas-2.2.3 propcache-0.3.1 pyarrow-20.0.0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.3 tzdata-2025.2 urllib3-2.4.0 xxhash-3.5.0 yarl-1.20.0\n",
      "Requirement already satisfied: pillow in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (11.2.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/10.4 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.0/10.4 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.7/10.4 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 11.4 MB/s eta 0:00:00\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "\n",
      "   ---------------------------------------- 0/4 [safetensors]\n",
      "   ---------- ----------------------------- 1/4 [regex]\n",
      "   -------------------- ------------------- 2/4 [tokenizers]\n",
      "   -------------------- ------------------- 2/4 [tokenizers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ---------------------------------------- 4/4 [transformers]\n",
      "\n",
      "Successfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install numpy matplotlib tqdm scikit-learn opencv-python\n",
    "!pip install datasets\n",
    "!pip install pillow\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69045b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa120d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뇌종양 데이터셋 클래스 정의\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, dataset_split, transform=None, mask_transform=None):\n",
    "        self.dataset = dataset_split\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        # 이미지 가져오기\n",
    "        image = item['image']\n",
    "        \n",
    "        # 세그멘테이션 마스크 생성\n",
    "        mask = np.zeros((item['height'], item['width']), dtype=np.uint8)\n",
    "        if len(item['segmentation']) > 0 and item['category_id'] == 1:  # 종양이 있는 경우\n",
    "            # 세그멘테이션 데이터를 마스크로 변환\n",
    "            for polygon in item['segmentation']:\n",
    "                # polygon은 [x1, y1, x2, y2, ...] 형태의 좌표 리스트\n",
    "                poly_array = np.array(polygon).reshape(-1, 2)\n",
    "                # fillPoly로 마스크 채우기\n",
    "                cv2.fillPoly(mask, [poly_array.astype(np.int32)], 1)\n",
    "        \n",
    "        # PIL 이미지로 변환\n",
    "        image_pil = Image.fromarray(np.array(image))\n",
    "        mask_pil = Image.fromarray(mask * 255)  # 0-1 마스크를 0-255로 변환\n",
    "        \n",
    "        # 변환 적용\n",
    "        if self.transform is not None:\n",
    "            image_pil = self.transform(image_pil)\n",
    "        \n",
    "        if self.mask_transform is not None:\n",
    "            mask_pil = self.mask_transform(mask_pil)\n",
    "        \n",
    "        return image_pil, mask_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe96fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HRNet 모델의 기본 블록들\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or inplanes != planes * self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or inplanes != planes * self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfac15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HRNet 모델 정의\n",
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels, num_channels, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.num_branches = num_branches\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "        \n",
    "        self.branches = self._make_branches(num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.num_inchannels[branch_index], num_channels[branch_index], stride))\n",
    "        \n",
    "        self.num_inchannels[branch_index] = num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(block(self.num_inchannels[branch_index], num_channels[branch_index]))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "        for i in range(num_branches):\n",
    "            branches.append(self._make_one_branch(i, block, num_blocks, num_channels))\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "        \n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        \n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    # 업샘플링\n",
    "                    fuse_layer.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_inchannels[j], num_inchannels[i], kernel_size=1, bias=False),\n",
    "                        nn.BatchNorm2d(num_inchannels[i]),\n",
    "                        nn.Upsample(scale_factor=2**(j-i), mode='nearest')\n",
    "                    ))\n",
    "                elif j == i:\n",
    "                    # 같은 해상도\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    # 다운샘플링\n",
    "                    ops = []\n",
    "                    for k in range(i - j):\n",
    "                        if k == i - j - 1:\n",
    "                            ops.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j], num_inchannels[i], kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                                nn.BatchNorm2d(num_inchannels[i])\n",
    "                            ))\n",
    "                        else:\n",
    "                            ops.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j], num_inchannels[j], kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                                nn.BatchNorm2d(num_inchannels[j]),\n",
    "                                nn.ReLU(inplace=True)\n",
    "                            ))\n",
    "                    fuse_layer.append(nn.Sequential(*ops))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "        \n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "        \n",
    "        if self.fuse_layers is not None:\n",
    "            y = []\n",
    "            for i in range(len(self.fuse_layers)):\n",
    "                y_branch = self.fuse_layers[i][0] if self.fuse_layers[i][0] is not None else x[0]\n",
    "                for j in range(1, self.num_branches):\n",
    "                    if self.fuse_layers[i][j] is not None:\n",
    "                        y_branch = y_branch + self.fuse_layers[i][j](x[j])\n",
    "                y.append(self.relu(y_branch))\n",
    "            \n",
    "            return y\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class HRNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=2):  # 배경 + 종양\n",
    "        super(HRNetV2, self).__init__()\n",
    "        # 스템 네트워크\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 스테이지 1\n",
    "        self.stage1_branch1 = self._make_layer(Bottleneck, 64, 64, 4)\n",
    "        self.transition1 = self._make_transition_layer([256], [32, 64])\n",
    "        \n",
    "        # 스테이지 2\n",
    "        self.stage2_branches = HighResolutionModule(\n",
    "            num_branches=2,\n",
    "            blocks=BasicBlock,\n",
    "            num_blocks=[4, 4],\n",
    "            num_inchannels=[32, 64],\n",
    "            num_channels=[32, 64]\n",
    "        )\n",
    "        \n",
    "        # 스테이지 3\n",
    "        self.transition2 = self._make_transition_layer([32, 64], [32, 64, 128])\n",
    "        self.stage3_branches = HighResolutionModule(\n",
    "            num_branches=3,\n",
    "            blocks=BasicBlock,\n",
    "            num_blocks=[4, 4, 4],\n",
    "            num_inchannels=[32, 64, 128],\n",
    "            num_channels=[32, 64, 128]\n",
    "        )\n",
    "        \n",
    "        # 스테이지 4\n",
    "        self.transition3 = self._make_transition_layer([32, 64, 128], [32, 64, 128, 256])\n",
    "        self.stage4_branches = HighResolutionModule(\n",
    "            num_branches=4,\n",
    "            blocks=BasicBlock,\n",
    "            num_blocks=[4, 4, 4, 4],\n",
    "            num_inchannels=[32, 64, 128, 256],\n",
    "            num_channels=[32, 64, 128, 256]\n",
    "        )\n",
    "        \n",
    "        # 세그멘테이션 헤드\n",
    "        self.head_channels = [32, 64, 128, 256]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(sum(self.head_channels), 256, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "        \n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_transition_layer(self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "        \n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                # 채널 수 조정\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i], num_channels_cur_layer[i], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(num_channels_cur_layer[i]),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    ))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                # 해상도 감소 및 채널 수 조정\n",
    "                conv_downsamples = []\n",
    "                for j in range(i - num_branches_pre + 1):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] if j == i - num_branches_pre else inchannels\n",
    "                    conv_downsamples.append(nn.Sequential(\n",
    "                        nn.Conv2d(inchannels, outchannels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannels),\n",
    "                        nn.ReLU(inplace=True)\n",
    "                    ))\n",
    "                transition_layers.append(nn.Sequential(*conv_downsamples))\n",
    "        \n",
    "        return nn.ModuleList(transition_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 스템 네트워크\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # 스테이지 1\n",
    "        x = self.stage1_branch1(x)\n",
    "        \n",
    "        # 스테이지 2\n",
    "        x_list = []\n",
    "        for i, trans in enumerate(self.transition1):\n",
    "            if trans is None:\n",
    "                x_list.append(x)\n",
    "            else:\n",
    "                x_list.append(trans(x))\n",
    "        y_list = self.stage2_branches(x_list)\n",
    "        \n",
    "        # 스테이지 3\n",
    "        x_list = []\n",
    "        for i, trans in enumerate(self.transition2):\n",
    "            if trans is None:\n",
    "                x_list.append(y_list[i])\n",
    "            else:\n",
    "                x_list.append(trans(y_list[-1]))\n",
    "        y_list = self.stage3_branches(x_list)\n",
    "        \n",
    "        # 스테이지 4\n",
    "        x_list = []\n",
    "        for i, trans in enumerate(self.transition3):\n",
    "            if trans is None:\n",
    "                x_list.append(y_list[i])\n",
    "            else:\n",
    "                x_list.append(trans(y_list[-1]))\n",
    "        y_list = self.stage4_branches(x_list)\n",
    "        \n",
    "        # 세그멘테이션 헤드를 위한 특징 맵 융합\n",
    "        y = torch.cat([\n",
    "            F.interpolate(y_list[0], size=y_list[0].size()[2:], mode='bilinear', align_corners=True),\n",
    "            F.interpolate(y_list[1], size=y_list[0].size()[2:], mode='bilinear', align_corners=True),\n",
    "            F.interpolate(y_list[2], size=y_list[0].size()[2:], mode='bilinear', align_corners=True),\n",
    "            F.interpolate(y_list[3], size=y_list[0].size()[2:], mode='bilinear', align_corners=True)\n",
    "        ], dim=1)\n",
    "        \n",
    "        # 세그멘테이션 헤드\n",
    "        y = self.head(y)\n",
    "        \n",
    "        # 원본 이미지 크기로 업샘플링\n",
    "        y = F.interpolate(y, scale_factor=4, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ed6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 및 로더 생성 함수\n",
    "def get_data_loaders(batch_size=8, val_split=0.2):\n",
    "    # 데이터셋 로드\n",
    "    dataset = load_dataset(\"dwb2023/brain-tumor-image-dataset-semantic-segmentation\")\n",
    "    \n",
    "    # 학습/검증 분할\n",
    "    train_dataset = dataset['train']\n",
    "    \n",
    "    # 데이터 변환\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    # 데이터셋 객체 생성\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(train_dataset)), \n",
    "        test_size=val_split, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    train_subset = [train_dataset[i] for i in train_indices]\n",
    "    val_subset = [train_dataset[i] for i in val_indices]\n",
    "    \n",
    "    train_dataset = BrainTumorDataset(train_subset, transform, mask_transform)\n",
    "    val_dataset = BrainTumorDataset(val_subset, transform, mask_transform)\n",
    "    \n",
    "    # 데이터 로더 생성\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e51fbf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 정의\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: [B, C, H, W], targets: [B, 1, H, W]\n",
    "        # 소프트맥스 적용\n",
    "        inputs = F.softmax(inputs, dim=1)\n",
    "        \n",
    "        # 종양 클래스에 대한 예측만 추출 (인덱스 1)\n",
    "        inputs = inputs[:, 1:2, :, :]\n",
    "        \n",
    "        # 평활화\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # 다이스 계수 계산\n",
    "        intersection = (inputs * targets).sum()\n",
    "        union = inputs.sum() + targets.sum()\n",
    "        \n",
    "        dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac98942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train_model(model, train_loader, val_loader, num_epochs=50, lr=1e-3, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    criterion = DiceLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 학습 모드\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # 예측\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # 역전파 및 최적화\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # 검증 모드\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # 모델 저장\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'hrnet_brain_tumor_best.pth')\n",
    "            print(f'Model saved with Val Loss: {best_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33fb9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/151 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, val_loader = get_data_loaders(batch_size=8)\n",
    "    \n",
    "    # 모델 생성\n",
    "    model = HRNetV2(num_classes=2)\n",
    "    \n",
    "    # 하드웨어 체크\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "    \n",
    "    # 학습 실행\n",
    "    train_model(model, train_loader, val_loader, num_epochs=50, lr=1e-3, device=device)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f8987",
   "metadata": {},
   "source": [
    "# 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477fb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904793a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, data_loader, device='cuda', threshold=0.5):\n",
    "    \"\"\"\n",
    "    모델 성능을 평가하는 다양한 지표를 계산합니다.\n",
    "    \n",
    "    Args:\n",
    "        model: 평가할 PyTorch 모델\n",
    "        data_loader: 테스트 데이터를 제공하는 DataLoader\n",
    "        device: 모델과 데이터를 실행할 장치 (default: 'cuda')\n",
    "        threshold: 이진 분류를 위한 임계값 (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        dict: 다양한 성능 지표를 포함하는 딕셔너리\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_score = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in data_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 소프트맥스 적용 (클래스가 2개 이상인 경우)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # 종양 클래스에 대한 확률 (보통 인덱스 1)\n",
    "            tumor_prob = probs[:, 1, :, :]\n",
    "            \n",
    "            # 예측 마스크 (임계값 적용)\n",
    "            pred_masks = (tumor_prob > threshold).float()\n",
    "            \n",
    "            # 배치의 모든 이미지에 대해 true와 pred 값 수집\n",
    "            for i in range(masks.size(0)):\n",
    "                # CPU로 이동하고 넘파이 배열로 변환\n",
    "                true_mask_np = masks[i].squeeze().cpu().numpy().flatten()\n",
    "                pred_mask_np = pred_masks[i].cpu().numpy().flatten()\n",
    "                tumor_prob_np = tumor_prob[i].cpu().numpy().flatten()\n",
    "                \n",
    "                y_true.append(true_mask_np)\n",
    "                y_pred.append(pred_mask_np)\n",
    "                y_score.append(tumor_prob_np)\n",
    "    \n",
    "    # 모든 배치의 결과를 하나의 배열로 연결\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_score = np.concatenate(y_score)\n",
    "    \n",
    "    # F1 점수 계산\n",
    "    f1 = f1_score(y_true > 0.5, y_pred > 0.5)\n",
    "    \n",
    "    # ROC-AUC 계산\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_score)\n",
    "    except:\n",
    "        roc_auc = 0.0\n",
    "        print(\"ROC-AUC 계산 중 오류가 발생했습니다. 일반적으로 클래스가 하나만 존재할 때 발생합니다.\")\n",
    "    \n",
    "    # IoU (Jaccard 인덱스) 계산\n",
    "    intersection = np.logical_and(y_true > 0.5, y_pred > 0.5).sum()\n",
    "    union = np.logical_or(y_true > 0.5, y_pred > 0.5).sum()\n",
    "    iou_score = intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    # Dice 점수 계산\n",
    "    dice_score = 2 * intersection / (np.sum(y_true > 0.5) + np.sum(y_pred > 0.5)) if (np.sum(y_true > 0.5) + np.sum(y_pred > 0.5)) > 0 else 0.0\n",
    "    \n",
    "    # 혼동 행렬 계산\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true > 0.5, y_pred > 0.5).ravel()\n",
    "    \n",
    "    # 정밀도, 재현율 계산\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    # 결과 반환\n",
    "    metrics = {\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'iou_score': iou_score,\n",
    "        'dice_score': dice_score,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'true_positives': tp,\n",
    "        'false_positives': fp,\n",
    "        'true_negatives': tn,\n",
    "        'false_negatives': fn\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc14a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model, data_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    ROC 곡선을 그립니다.\n",
    "    \n",
    "    Args:\n",
    "        model: 평가할 PyTorch 모델\n",
    "        data_loader: 테스트 데이터를 제공하는 DataLoader\n",
    "        device: 모델과 데이터를 실행할 장치 (default: 'cuda')\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    y_true = []\n",
    "    y_score = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in data_loader:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 소프트맥스 적용 (클래스가 2개 이상인 경우)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # 종양 클래스에 대한 확률 (보통 인덱스 1)\n",
    "            tumor_prob = probs[:, 1, :, :]\n",
    "            \n",
    "            # 배치의 모든 이미지에 대해 true와 score 값 수집\n",
    "            for i in range(masks.size(0)):\n",
    "                true_mask_np = masks[i].squeeze().cpu().numpy().flatten()\n",
    "                tumor_prob_np = tumor_prob[i].cpu().numpy().flatten()\n",
    "                \n",
    "                y_true.append(true_mask_np > 0.5)\n",
    "                y_score.append(tumor_prob_np)\n",
    "    \n",
    "    # 모든 배치의 결과를 하나의 배열로 연결\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_score = np.concatenate(y_score)\n",
    "    \n",
    "    # ROC 곡선 계산\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # ROC 곡선 그리기\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fpr, tpr, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db1f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(model, data_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    정밀도-재현율 곡선을 그립니다.\n",
    "    \n",
    "    Args:\n",
    "        model: 평가할 PyTorch 모델\n",
    "        data_loader: 테스트 데이터를 제공하는 DataLoader\n",
    "        device: 모델과 데이터를 실행할 장치 (default: 'cuda')\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    y_true = []\n",
    "    y_score = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in data_loader:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 소프트맥스 적용 (클래스가 2개 이상인 경우)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # 종양 클래스에 대한 확률 (보통 인덱스 1)\n",
    "            tumor_prob = probs[:, 1, :, :]\n",
    "            \n",
    "            # 배치의 모든 이미지에 대해 true와 score 값 수집\n",
    "            for i in range(masks.size(0)):\n",
    "                true_mask_np = masks[i].squeeze().cpu().numpy().flatten()\n",
    "                tumor_prob_np = tumor_prob[i].cpu().numpy().flatten()\n",
    "                \n",
    "                y_true.append(true_mask_np > 0.5)\n",
    "                y_score.append(tumor_prob_np)\n",
    "    \n",
    "    # 모든 배치의 결과를 하나의 배열로 연결\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_score = np.concatenate(y_score)\n",
    "    \n",
    "    # 정밀도-재현율 곡선 계산\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "    avg_precision = average_precision_score(y_true, y_score)\n",
    "    \n",
    "    # 정밀도-재현율 곡선 그리기\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(recall, precision, color='darkorange', lw=2, label=f'PR curve (AP = {avg_precision:.3f})')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('precision_recall_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return precision, recall, avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_results(model, data_loader, num_samples=5, device='cuda', threshold=0.5):\n",
    "    \"\"\"\n",
    "    모델의 세그멘테이션 결과를 시각화합니다.\n",
    "    \n",
    "    Args:\n",
    "        model: 평가할 PyTorch 모델\n",
    "        data_loader: 테스트 데이터를 제공하는 DataLoader\n",
    "        num_samples: 시각화할 샘플 수 (default: 5)\n",
    "        device: 모델과 데이터를 실행할 장치 (default: 'cuda')\n",
    "        threshold: 이진 분류를 위한 임계값 (default: 0.5)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 시각화를 위한 샘플 가져오기\n",
    "    images_list = []\n",
    "    masks_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in data_loader:\n",
    "            if len(images_list) >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 소프트맥스 적용 (클래스가 2개 이상인 경우)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # 종양 클래스에 대한 확률 (보통 인덱스 1)\n",
    "            tumor_prob = probs[:, 1, :, :]\n",
    "            \n",
    "            # 예측 마스크 (임계값 적용)\n",
    "            pred_masks = (tumor_prob > threshold).float()\n",
    "            \n",
    "            # CPU로 이동\n",
    "            images_cpu = images.cpu()\n",
    "            masks_cpu = masks.cpu()\n",
    "            preds_cpu = pred_masks.cpu()\n",
    "            \n",
    "            # 각 배치의 이미지 추가\n",
    "            for i in range(min(images.size(0), num_samples - len(images_list))):\n",
    "                images_list.append(images_cpu[i])\n",
    "                masks_list.append(masks_cpu[i])\n",
    "                preds_list.append(preds_cpu[i])\n",
    "    \n",
    "    # 결과 시각화\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # 원본 이미지\n",
    "        img = images_list[i].permute(1, 2, 0).numpy()\n",
    "        # 정규화 복원 (ImageNet 평균, 표준편차 사용 가정)\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # 실제 마스크\n",
    "        mask = masks_list[i].squeeze().numpy()\n",
    "        \n",
    "        # 예측 마스크\n",
    "        pred = preds_list[i].squeeze().numpy()\n",
    "        \n",
    "        # 그리기\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title('Original Image')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth Mask')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(pred, cmap='gray')\n",
    "        axes[i, 2].set_title('Predicted Mask')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('segmentation_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    모델을 평가하고 모든 지표를 출력합니다.\n",
    "    \n",
    "    Args:\n",
    "        model: 평가할 PyTorch 모델\n",
    "        test_loader: 테스트 데이터를 제공하는 DataLoader\n",
    "        device: 모델과 데이터를 실행할 장치 (default: 'cuda')\n",
    "    \"\"\"\n",
    "    print(\"모델 평가 중...\")\n",
    "    # 성능 지표 계산\n",
    "    metrics = calculate_metrics(model, test_loader, device)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\n=== 모델 평가 결과 ===\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"IoU Score: {metrics['iou_score']:.4f}\")\n",
    "    print(f\"Dice Score: {metrics['dice_score']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(\"\\n=== 혼동 행렬 ===\")\n",
    "    print(f\"True Positives: {metrics['true_positives']}\")\n",
    "    print(f\"False Positives: {metrics['false_positives']}\")\n",
    "    print(f\"True Negatives: {metrics['true_negatives']}\")\n",
    "    print(f\"False Negatives: {metrics['false_negatives']}\")\n",
    "    \n",
    "    # ROC 곡선 그리기\n",
    "    print(\"\\n그래프 생성 중...\")\n",
    "    plot_roc_curve(model, test_loader, device)\n",
    "    \n",
    "    # 정밀도-재현율 곡선 그리기\n",
    "    plot_precision_recall_curve(model, test_loader, device)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    visualize_results(model, test_loader, num_samples=5, device=device)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 사용 예시\n",
    "def example_usage():\n",
    "    # 모델 로드\n",
    "    model = HRNetV2(num_classes=2)  # 이전에 정의한 HRNetV2 클래스 사용\n",
    "    model.load_state_dict(torch.load('hrnet_brain_tumor_best.pth'))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 데이터 로더 생성 (테스트 데이터만)\n",
    "    _, test_loader = get_data_loaders(batch_size=8, val_split=0.2)  # 이전에 정의한 함수 사용\n",
    "    \n",
    "    # 모델 평가\n",
    "    metrics = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # 결과 저장\n",
    "    with open('evaluation_results.txt', 'w') as f:\n",
    "        f.write(\"=== 모델 평가 결과 ===\\n\")\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
