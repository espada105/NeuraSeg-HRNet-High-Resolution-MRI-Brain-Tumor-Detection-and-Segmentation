{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOsdKaEOIxB+sdK9Mww4M/m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R9AO17TmShbm","executionInfo":{"status":"ok","timestamp":1746265034383,"user_tz":-540,"elapsed":36563,"user":{"displayName":"김재원","userId":"17117179462261737652"}},"outputId":"ae3f70b4-6830-4bce-b560-58af3b1462ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","fatal: destination path 'HRNet-Image-Classification' already exists and is not an empty directory.\n","/content/HRNet-Image-Classification\n","Collecting EasyDict==1.7 (from -r requirements.txt (line 1))\n","  Using cached easydict-1.7.tar.gz (6.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.17.61, 4.4.0.42, 4.4.0.44, 4.5.4.58, 4.5.5.62, 4.7.0.68\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==3.4.1.15 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84, 4.11.0.86)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==3.4.1.15\u001b[0m\u001b[31m\n","\u001b[0m/content\n","--2025-05-03 09:36:42--  https://github.com/HRNet/HRNet-Image-Classification/releases/download/PretrainedWeights/HRNet_W48_C_ssld_pretrained.pth\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/180518813/682a2c80-5b14-11eb-8711-1a6e6779f0e7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250503%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250503T093642Z&X-Amz-Expires=300&X-Amz-Signature=2b6dbe17846da990b42057b23449797ff01c3bdee48ff12394a8c1e7c62b5825&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DHRNet_W48_C_ssld_pretrained.pth&response-content-type=application%2Foctet-stream [following]\n","--2025-05-03 09:36:42--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/180518813/682a2c80-5b14-11eb-8711-1a6e6779f0e7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250503%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250503T093642Z&X-Amz-Expires=300&X-Amz-Signature=2b6dbe17846da990b42057b23449797ff01c3bdee48ff12394a8c1e7c62b5825&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DHRNet_W48_C_ssld_pretrained.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 310534219 (296M) [application/octet-stream]\n","Saving to: ‘/content/HRNet_W48_C_ssld_pretrained.pth’\n","\n","/content/HRNet_W48_ 100%[===================>] 296.15M  7.09MB/s    in 31s     \n","\n","2025-05-03 09:37:14 (9.65 MB/s) - ‘/content/HRNet_W48_C_ssld_pretrained.pth’ saved [310534219/310534219]\n","\n"]}],"source":["# 필요한 라이브러리 설치\n","!pip install datasets torch torchvision scikit-learn matplotlib\n","!git clone https://github.com/HRNet/HRNet-Image-Classification\n","%cd HRNet-Image-Classification\n","!pip install -r requirements.txt\n","%cd ..\n","\n","!wget -O /content/HRNet_W48_C_ssld_pretrained.pth https://github.com/HRNet/HRNet-Image-Classification/releases/download/PretrainedWeights/HRNet_W48_C_ssld_pretrained.pth\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","from datasets import load_dataset\n","import numpy as np\n","from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, recall_score, precision_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["# HRNet 모델 임포트\n","import sys\n","sys.path.append('HRNet-Image-Classification/lib')\n","from models.cls_hrnet import get_cls_net\n","\n","# 데이터셋 로드\n","dataset = load_dataset(\"dwb2023/brain-tumor-image-dataset-semantic-segmentation\")\n","train = dataset[\"train\"]\n","test = dataset[\"test\"]\n","valid = dataset[\"valid\"]\n","\n","# 이미지 전처리 파이프라인 (강화된 증강)\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.Lambda(lambda x: x.convert('RGB') if x.mode != 'RGB' else x),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"],"metadata":{"id":"b_hdUPRrT_vc","executionInfo":{"status":"ok","timestamp":1746265039910,"user_tz":-540,"elapsed":3252,"user":{"displayName":"김재원","userId":"17117179462261737652"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# 커스텀 데이터셋 클래스\n","class BrainTumorDataset(Dataset):\n","    def __init__(self, dataset, transform=None):\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        image = self.dataset[idx][\"image\"]\n","        label = self.dataset[idx][\"category_id\"]  # 원본 유지 (1=Tumor, 2=Normal)\n","        if self.transform:\n","            image = self.transform(image)\n","        # 레이블을 [0,1] 범위로 조정하지 않고 원본 값 유지\n","        return image, torch.tensor(label, dtype=torch.float32)\n","\n","# 데이터로더 생성\n","train_dataset = BrainTumorDataset(train, transform=transform)\n","valid_dataset = BrainTumorDataset(valid, transform=transform)\n","test_dataset = BrainTumorDataset(test, transform=transform)\n","\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"],"metadata":{"id":"5YyzzxVzUDuK","executionInfo":{"status":"ok","timestamp":1746265041039,"user_tz":-540,"elapsed":2,"user":{"displayName":"김재원","userId":"17117179462261737652"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# HRNet-W48-C-ssld 공식 모델 구성\n","hrnet_config = {\n","    'MODEL': {\n","        'NAME': 'cls_hrnet_w48',\n","        'EXTRA': {\n","            'STAGE1': {\n","                'NUM_MODULES': 1,\n","                'NUM_BRANCHES': 1,\n","                'BLOCK': 'BOTTLENECK',\n","                'NUM_BLOCKS': [4],\n","                'NUM_CHANNELS': [64],\n","                'FUSE_METHOD': 'SUM'\n","            },\n","            'STAGE2': {\n","                'NUM_MODULES': 1,\n","                'NUM_BRANCHES': 2,\n","                'BLOCK': 'BASIC',\n","                'NUM_BLOCKS': [4,4],\n","                'NUM_CHANNELS': [48, 96],\n","                'FUSE_METHOD': 'SUM'\n","            },\n","            'STAGE3': {\n","                'NUM_MODULES': 4,\n","                'NUM_BRANCHES': 3,\n","                'BLOCK': 'BASIC',\n","                'NUM_BLOCKS': [4,4,4],\n","                'NUM_CHANNELS': [48, 96, 192],\n","                'FUSE_METHOD': 'SUM'\n","            },\n","            'STAGE4': {\n","                'NUM_MODULES': 3,\n","                'NUM_BRANCHES': 4,\n","                'BLOCK': 'BASIC',\n","                'NUM_BLOCKS': [4,4,4,4],\n","                'NUM_CHANNELS': [48, 96, 192, 384],\n","                'FUSE_METHOD': 'SUM'\n","            }\n","        },\n","        'NUM_CLASSES': 1000\n","    }\n","}\n","\n","# 모델 초기화 및 사전학습 가중치 로드\n","model = get_cls_net(hrnet_config)\n","pretrained_dict = torch.load('/content/HRNet_W48_C_ssld_pretrained.pth')\n","model.load_state_dict(pretrained_dict, strict=False)\n","\n","# 안정적인 분류기 구조 (2-layer MLP)\n","model.classifier = nn.Sequential(\n","    nn.Linear(model.classifier.in_features, 512),\n","    nn.BatchNorm1d(512),\n","    nn.ReLU(),\n","    nn.Dropout(0.5),\n","    nn.Linear(512, 1)\n",")"],"metadata":{"id":"Q5-v_904UGRX","executionInfo":{"status":"ok","timestamp":1746265044728,"user_tz":-540,"elapsed":2420,"user":{"displayName":"김재원","userId":"17117179462261737652"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Focal Loss 정의 (클래스 불균형 대응)\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.8, gamma=2.0, eps=1e-6):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.eps = eps\n","\n","    def forward(self, inputs, targets):\n","        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n","        pt = torch.exp(-BCE_loss)\n","        pt = torch.clamp(pt, self.eps, 1.0 - self.eps)  # NaN 방지\n","        loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n","        return loss.mean()\n","\n","# 학습 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","criterion = FocalLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n","\n","# Gradient Clipping 함수\n","def clip_gradient(optimizer, grad_clip):\n","    for group in optimizer.param_groups:\n","        for param in group['params']:\n","            if param.grad is not None:\n","                param.grad.data.clamp_(-grad_clip, grad_clip)\n"],"metadata":{"id":"ghu7kRQDUKg4","executionInfo":{"status":"ok","timestamp":1746265047144,"user_tz":-540,"elapsed":142,"user":{"displayName":"김재원","userId":"17117179462261737652"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# 학습 루프\n","num_epochs = 10\n","best_val_auc = 0\n","grad_clip = 1.0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    total_samples = 0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images).squeeze()\n","\n","        # 레이블 변환: 2(Normal)→0, 1(Tumor)→1\n","        labels_binary = torch.where(labels == 1, 1.0, 0.0)\n","        loss = criterion(outputs, labels_binary)\n","\n","        loss.backward()\n","        clip_gradient(optimizer, grad_clip)\n","        optimizer.step()\n","\n","        train_loss += loss.item() * images.size(0)\n","        total_samples += images.size(0)\n","\n","    train_loss /= total_samples\n","    scheduler.step()\n","\n","    # 검증 단계\n","    model.eval()\n","    val_probs, val_labels = [], []\n","    with torch.no_grad():\n","        for images, labels in valid_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images).squeeze()\n","            val_probs.extend(torch.sigmoid(outputs).cpu().numpy())\n","            val_labels.extend(labels.cpu().numpy())\n","\n","    # 레이블 변환: 2→0, 1→1\n","    val_labels_binary = np.where(np.array(val_labels) == 1, 1, 0)\n","    val_preds = (np.array(val_probs) > 0.5).astype(int)\n","\n","    # 평가 지표 계산\n","    val_f1 = f1_score(val_labels_binary, val_preds)\n","    val_recall = recall_score(val_labels_binary, val_preds)\n","    val_precision = precision_score(val_labels_binary, val_preds)\n","    val_auc = roc_auc_score(val_labels_binary, val_probs)\n","    tn, fp, fn, tp = confusion_matrix(val_labels_binary, val_preds).ravel()\n","    val_iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0.0\n","\n","    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f} | Val F1: {val_f1:.4f} | Val Recall: {val_recall:.4f}\")\n","    print(f\"Val Precision: {val_precision:.4f} | Val IoU: {val_iou:.4f} | Val AUC: {val_auc:.4f}\")\n","\n","    # 최고 모델 저장\n","    if val_auc > best_val_auc:\n","        best_val_auc = val_auc\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': train_loss,\n","            'auc': val_auc\n","        }, 'best_model.pth')\n","        print(f\"New best model saved with AUC: {val_auc:.4f}\")\n","\n","# 테스트 평가\n","checkpoint = torch.load('best_model.pth')\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.eval()\n","\n","test_probs, test_labels = [], []\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images).squeeze()\n","        test_probs.extend(torch.sigmoid(outputs).cpu().numpy())\n","        test_labels.extend(labels.cpu().numpy())\n","\n","# 레이블 변환: 2→0, 1→1\n","test_labels_binary = np.where(np.array(test_labels) == 1, 1, 0)\n","test_preds = (np.array(test_probs) > 0.5).astype(int)\n","\n","# 평가 지표 계산\n","test_f1 = f1_score(test_labels_binary, test_preds)\n","test_recall = recall_score(test_labels_binary, test_preds)\n","test_precision = precision_score(test_labels_binary, test_preds)\n","test_auc = roc_auc_score(test_labels_binary, test_probs)\n","tn, fp, fn, tp = confusion_matrix(test_labels_binary, test_preds).ravel()\n","test_iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0.0\n","\n","# 최종 결과 출력\n","print(\"\\n=== 최종 테스트 성능 ===\")\n","print(f\"F1-score: {test_f1:.4f}\")\n","print(f\"Recall (Tumor): {test_recall:.4f} [TP:{tp}/FN:{fn}]\")\n","print(f\"Precision (Tumor): {test_precision:.4f} [TP:{tp}/FP:{fp}]\")\n","print(f\"IoU (Tumor): {test_iou:.4f}\")\n","print(f\"ROC-AUC: {test_auc:.4f}\")\n","\n","# 혼동 행렬 시각화\n","conf_mat = confusion_matrix(test_labels_binary, test_preds)\n","plt.figure(figsize=(8,6))\n","sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=['Normal','Tumor'],\n","            yticklabels=['Normal','Tumor'])\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title(f'Confusion Matrix\\nRecall: {test_recall:.2%}, Precision: {test_precision:.2%}')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UhZEvlhYW3-m","executionInfo":{"status":"error","timestamp":1746266344778,"user_tz":-540,"elapsed":976447,"user":{"displayName":"김재원","userId":"17117179462261737652"}},"outputId":"5e5c9a13-39a1-4b00-a12c-111249546db0"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/10\n","Train Loss: 0.0080 | Val F1: 0.9766 | Val Recall: 0.9952\n","Val Precision: 0.9587 | Val IoU: 0.9543 | Val AUC: 0.9973\n","New best model saved with AUC: 0.9973\n","\n","Epoch 2/10\n","Train Loss: 0.0051 | Val F1: 0.9789 | Val Recall: 0.9952\n","Val Precision: 0.9631 | Val IoU: 0.9587 | Val AUC: 0.9992\n","New best model saved with AUC: 0.9992\n","\n","Epoch 3/10\n","Train Loss: 0.0022 | Val F1: 0.9904 | Val Recall: 0.9810\n","Val Precision: 1.0000 | Val IoU: 0.9810 | Val AUC: 0.9975\n","\n","Epoch 4/10\n","Train Loss: 0.0015 | Val F1: 0.9952 | Val Recall: 0.9905\n","Val Precision: 1.0000 | Val IoU: 0.9905 | Val AUC: 0.9988\n","\n","Epoch 5/10\n","Train Loss: 0.0012 | Val F1: 0.9952 | Val Recall: 0.9905\n","Val Precision: 1.0000 | Val IoU: 0.9905 | Val AUC: 0.9997\n","New best model saved with AUC: 0.9997\n","\n","Epoch 6/10\n","Train Loss: 0.0019 | Val F1: 0.9976 | Val Recall: 0.9952\n","Val Precision: 1.0000 | Val IoU: 0.9952 | Val AUC: 0.9993\n","\n","Epoch 7/10\n","Train Loss: 0.0009 | Val F1: 0.9928 | Val Recall: 0.9905\n","Val Precision: 0.9952 | Val IoU: 0.9858 | Val AUC: 0.9997\n","\n","Epoch 8/10\n","Train Loss: 0.0013 | Val F1: 0.9952 | Val Recall: 0.9905\n","Val Precision: 1.0000 | Val IoU: 0.9905 | Val AUC: 0.9997\n","\n","Epoch 9/10\n","Train Loss: 0.0007 | Val F1: 0.9952 | Val Recall: 0.9905\n","Val Precision: 1.0000 | Val IoU: 0.9905 | Val AUC: 0.9988\n","\n","Epoch 10/10\n","Train Loss: 0.0006 | Val F1: 0.9976 | Val Recall: 0.9952\n","Val Precision: 1.0000 | Val IoU: 0.9952 | Val AUC: 0.9978\n"]},{"output_type":"error","ename":"UnpicklingError","evalue":"Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-8927156f04fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# 테스트 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."]}]}]}