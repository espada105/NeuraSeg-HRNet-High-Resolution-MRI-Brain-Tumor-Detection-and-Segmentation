{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall torch torchvision torchaudio\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA 디바이스 수: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"현재 CUDA 디바이스: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA 디바이스 이름: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e0f7d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 로드 중...\n",
      "데이터셋 로드 완료!\n",
      "\n",
      "==== GPU 디버그 정보 ====\n",
      "CUDA 사용 가능: False\n",
      "=======================\n",
      "\n",
      "메모리 최적화된 뇌종양 세그멘테이션 - 경량화 모델 (5GB 미만 메모리 사용)\n",
      "==================================================\n",
      "PyTorch 버전: 2.7.0+cpu\n",
      "GPU를 사용할 수 없습니다. CPU 모드로 실행됩니다.\n",
      "데이터 로더 생성 완료! 훈련 샘플 수: 1502\n",
      "경량화 모델 생성 중...\n",
      "사용 가능한 HRNet 모델: ['hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w18_ssld', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w48_ssld', 'hrnet_w64']\n",
      "선택된 모델: hrnet_w18_small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 생성 완료!\n",
      "모델 총 파라미터 수: 3,131,681\n",
      "트레이너 설정 중...\n",
      "트레이너 초기화 오류: `devices` selected with `CPUAccelerator` should be an int > 0.\n",
      "대체 설정으로 시도합니다...\n",
      "대체 트레이너 초기화 오류: Trainer.__init__() got an unexpected keyword argument 'gpus'\n",
      "최소 설정으로 시도합니다...\n",
      "GPU를 사용할 수 없습니다. CPU 모드로 실행합니다.\n",
      "모델 훈련 시작...\n",
      "오류 발생: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n",
      "최종 메모리 사용량:\n",
      "GPU를 사용할 수 없습니다. CPU 모드로 실행합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tjddl\\AppData\\Local\\Temp\\ipykernel_9964\\1342225758.py\", line 588, in main\n",
      "    trainer.fit(model, train_loader, val_loader)\n",
      "  File \"c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 561, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py\", line 48, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 599, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\", line 988, in _run\n",
      "    self.strategy.setup(self)\n",
      "  File \"c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\", line 159, in setup\n",
      "    self.setup_optimizers(trainer)\n",
      "  File \"c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\", line 139, in setup_optimizers\n",
      "    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py\", line 180, in _init_optimizers_and_lr_schedulers\n",
      "    optim_conf = call._call_lightning_module_hook(model.trainer, \"configure_optimizers\", pl_module=model)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\GitHubRepo\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py\", line 176, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\tjddl\\AppData\\Local\\Temp\\ipykernel_9964\\1342225758.py\", line 355, in configure_optimizers\n",
      "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'\n"
     ]
    }
   ],
   "source": [
    "# GPU 강제 활성화된 메모리 최적화 HRNet 뇌종양 세그멘테이션 모델 (5GB 미만 메모리 사용)\n",
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from albumentations import Compose, Resize, Normalize, HorizontalFlip, VerticalFlip, RandomRotate90\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from datasets import load_dataset\n",
    "import timm\n",
    "\n",
    "# GPU 메모리 제한 설정 - 5GB 미만 사용\n",
    "if torch.cuda.is_available():\n",
    "    # 메모리 제한 설정 (바이트 단위, 5GB = 5 * 1024 * 1024 * 1024)\n",
    "    torch.cuda.set_per_process_memory_fraction(0.6)  # GPU 메모리의 60%만 사용\n",
    "    print(f\"GPU 메모리 제한: 전체 메모리의 60%\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 메모리 사용량 추적 함수\n",
    "def print_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated() / (1024**3):.3f} GB / {torch.cuda.memory_reserved() / (1024**3):.3f} GB\")\n",
    "    else:\n",
    "        print(\"GPU를 사용할 수 없습니다. CPU 모드로 실행합니다.\")\n",
    "\n",
    "# 메모리 최적화 함수\n",
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "# 랜덤 시드 설정\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# 데이터셋 로드\n",
    "print(\"데이터셋 로드 중...\")\n",
    "dataset = load_dataset(\"dwb2023/brain-tumor-image-dataset-semantic-segmentation\")\n",
    "print(\"데이터셋 로드 완료!\")\n",
    "\n",
    "# 데이터 전처리 및 증강\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, split='train', img_size=160):  # 이미지 크기를 160으로 설정\n",
    "        self.dataset = hf_dataset[split]\n",
    "        self.img_size = img_size\n",
    "        self.split = split\n",
    "        self.transform = self.get_transforms(split)\n",
    "        \n",
    "        # 훈련 데이터 크기 제한 - 주석 해제하여 사용 가능\n",
    "        # if split == 'train':\n",
    "        #     self.dataset = self.dataset.select(range(min(len(self.dataset), 500)))\n",
    "        # elif split == 'valid' or split == 'test':\n",
    "        #     self.dataset = self.dataset.select(range(min(len(self.dataset), 100)))\n",
    "            \n",
    "    def get_transforms(self, split):\n",
    "        if split == 'train':\n",
    "            # 훈련 세트에는 가벼운 데이터 증강만 적용\n",
    "            return Compose([\n",
    "                Resize(self.img_size, self.img_size),\n",
    "                HorizontalFlip(p=0.5),\n",
    "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        else:\n",
    "            # 검증/테스트 세트에는 기본 전처리만 적용\n",
    "            return Compose([\n",
    "                Resize(self.img_size, self.img_size),\n",
    "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "\n",
    "    def create_mask_from_segmentation(self, segmentation, height, width):\n",
    "        # segmentation (다각형 좌표)에서 마스크 생성\n",
    "        mask = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "        if segmentation and isinstance(segmentation, list):\n",
    "            for polygon in segmentation:\n",
    "                if len(polygon) > 4:  # 최소 3개의 좌표(x,y) 쌍이 필요\n",
    "                    # [x1, y1, x2, y2, ...] 형식을 (N, 2) 형식으로 변환\n",
    "                    points = np.array(polygon).reshape(-1, 2).astype(np.int32)\n",
    "                    cv2.fillPoly(mask, [points], 1)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = np.array(item['image'])\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        # segmentation에서 마스크 생성\n",
    "        mask = self.create_mask_from_segmentation(item['segmentation'], height, width)\n",
    "\n",
    "        # 이미지 및 마스크 전처리\n",
    "        transformed = self.transform(image=image, mask=mask)\n",
    "        image = transformed['image']\n",
    "        mask = transformed['mask'].unsqueeze(0)  # 채널 차원 추가 [1, H, W]\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# 데이터 로더 생성 (메모리 최적화)\n",
    "def create_dataloaders(dataset, batch_size=2):  # 배치 크기를 더 줄임\n",
    "    train_dataset = BrainTumorDataset(dataset, 'train')\n",
    "    val_dataset = BrainTumorDataset(dataset, 'valid')\n",
    "    test_dataset = BrainTumorDataset(dataset, 'test')\n",
    "\n",
    "    # num_workers 및 핀 메모리 설정\n",
    "    num_workers = 2 if torch.cuda.is_available() else 0\n",
    "    pin_memory = torch.cuda.is_available()\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                             num_workers=num_workers, pin_memory=pin_memory)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                           num_workers=num_workers, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                            num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Dice 손실 함수 정의\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "        # 분자 (intersection)\n",
    "        intersection = torch.sum(y_true * y_pred)\n",
    "\n",
    "        # 분모 (union)\n",
    "        union = torch.sum(y_true) + torch.sum(y_pred)\n",
    "\n",
    "        # Dice 계수\n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "\n",
    "        return 1.0 - dice  # 최소화를 위해 1에서 빼기\n",
    "\n",
    "# 조합 손실 함수 (간소화)\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "        # Dice 손실\n",
    "        intersection = torch.sum(y_true * y_pred)\n",
    "        union = torch.sum(y_true) + torch.sum(y_pred)\n",
    "        dice_loss = 1.0 - (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "\n",
    "        return dice_loss\n",
    "\n",
    "# 더 가벼운 HRNet 모델 사용 (HRNet-W18 Small 또는 ResNet18)\n",
    "class LightHRNetSegmentation(pl.LightningModule):\n",
    "    def __init__(self, num_classes=1, lr=0.001, weight_decay=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # 간소화된 손실 함수\n",
    "        self.criterion = CombinedLoss()\n",
    "\n",
    "        # 성능 메트릭 저장\n",
    "        self.best_val_f1 = 0.0\n",
    "\n",
    "        # 사용 가능한 모델 확인\n",
    "        try:\n",
    "            # 사용 가능한 HRNet 모델 확인\n",
    "            available_models = [m for m in timm.list_models() if 'hrnet' in m]\n",
    "            print(f\"사용 가능한 HRNet 모델: {available_models}\")\n",
    "            \n",
    "            # 가장 가벼운 HRNet 모델 선택\n",
    "            if 'hrnet_w18_small' in available_models:\n",
    "                model_name = 'hrnet_w18_small'\n",
    "            elif 'hrnet_w18' in available_models:\n",
    "                model_name = 'hrnet_w18'\n",
    "            else:\n",
    "                model_name = 'resnet18'  # 대체 모델\n",
    "                \n",
    "            print(f\"선택된 모델: {model_name}\")\n",
    "            \n",
    "            if 'hrnet' in model_name:\n",
    "                self.backbone = timm.create_model(\n",
    "                    model_name, \n",
    "                    pretrained=True,\n",
    "                    features_only=True\n",
    "                )\n",
    "            else:\n",
    "                # ResNet18 사용\n",
    "                self.backbone = timm.create_model(\n",
    "                    'resnet18', \n",
    "                    pretrained=True,\n",
    "                    features_only=True\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"모델 로드 실패: {e}\")\n",
    "            print(\"ResNet18 모델로 대체합니다.\")\n",
    "            # ResNet18 백업 모델 사용\n",
    "            self.backbone = timm.create_model(\n",
    "                'resnet18', \n",
    "                pretrained=True,\n",
    "                features_only=True\n",
    "            )\n",
    "\n",
    "        # 마지막 특성 맵의 채널 수\n",
    "        last_channels = self.backbone.feature_info[-1]['num_chs']\n",
    "\n",
    "        # 가벼운 세그멘테이션 헤드\n",
    "        self.segmentation_head = nn.Sequential(\n",
    "            nn.Conv2d(last_channels, 32, kernel_size=3, padding=1),  # 채널 수 줄임\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력 크기 저장\n",
    "        input_size = x.shape[2:]\n",
    "\n",
    "        # 백본으로 특성 추출\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        # 마지막 특성 맵 사용\n",
    "        last_feature = features[-1]\n",
    "\n",
    "        # 세그멘테이션 헤드 통과\n",
    "        logits = self.segmentation_head(last_feature)\n",
    "\n",
    "        # 원래 이미지 크기로 업샘플링\n",
    "        if logits.shape[2:] != input_size:\n",
    "            logits = F.interpolate(logits, size=input_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        predictions = self(images)\n",
    "        loss = self.criterion(predictions, masks)\n",
    "\n",
    "        # F1 스코어 계산\n",
    "        pred_masks = (torch.sigmoid(predictions) > 0.5).float()\n",
    "        f1 = self.calculate_f1_score(pred_masks, masks)\n",
    "\n",
    "        # 로깅\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_f1', f1, prog_bar=True)\n",
    "\n",
    "        # 메모리 정리\n",
    "        if batch_idx % 20 == 0:\n",
    "            clean_memory()\n",
    "            \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        predictions = self(images)\n",
    "        loss = self.criterion(predictions, masks)\n",
    "\n",
    "        # F1 스코어 계산\n",
    "        pred_masks = (torch.sigmoid(predictions) > 0.5).float()\n",
    "        f1 = self.calculate_f1_score(pred_masks, masks)\n",
    "        \n",
    "        # 로깅\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_f1', f1, prog_bar=True)\n",
    "\n",
    "        # 최고 F1 스코어 업데이트\n",
    "        if f1 > self.best_val_f1:\n",
    "            self.best_val_f1 = f1\n",
    "\n",
    "        return {'val_loss': loss, 'val_f1': f1}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, masks = batch\n",
    "        predictions = self(images)\n",
    "\n",
    "        # F1 스코어 계산\n",
    "        pred_masks = (torch.sigmoid(predictions) > 0.5).float()\n",
    "        f1 = self.calculate_f1_score(pred_masks, masks)\n",
    "        precision = self.calculate_precision(pred_masks, masks)\n",
    "        recall = self.calculate_recall(pred_masks, masks)\n",
    "        \n",
    "        # 로깅\n",
    "        self.log('test_f1', f1)\n",
    "        self.log('test_precision', precision)\n",
    "        self.log('test_recall', recall)\n",
    "\n",
    "        return {'test_f1': f1, 'test_precision': precision, 'test_recall': recall}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, _ = batch\n",
    "        predictions = self(images)\n",
    "        pred_masks = (torch.sigmoid(predictions) > 0.5).float()\n",
    "        return pred_masks\n",
    "\n",
    "    def calculate_f1_score(self, pred, target):\n",
    "        # CPU 사용하여 메모리 부담 감소\n",
    "        pred_flat = pred.view(-1).cpu().detach().numpy()\n",
    "        target_flat = target.view(-1).cpu().detach().numpy()\n",
    "\n",
    "        # 예측값이 0.5보다 크면 1, 아니면 0\n",
    "        pred_binary = (pred_flat > 0.5).astype(np.int32)\n",
    "        target_binary = (target_flat > 0.5).astype(np.int32)\n",
    "\n",
    "        # F1 스코어 계산\n",
    "        f1 = f1_score(target_binary, pred_binary, zero_division=1)\n",
    "        return torch.tensor(f1)\n",
    "\n",
    "    def calculate_precision(self, pred, target):\n",
    "        # CPU 사용하여 메모리 부담 감소\n",
    "        pred_flat = pred.view(-1).cpu().detach().numpy()\n",
    "        target_flat = target.view(-1).cpu().detach().numpy()\n",
    "\n",
    "        pred_binary = (pred_flat > 0.5).astype(np.int32)\n",
    "        target_binary = (target_flat > 0.5).astype(np.int32)\n",
    "\n",
    "        precision = precision_score(target_binary, pred_binary, zero_division=1)\n",
    "        return torch.tensor(precision)\n",
    "\n",
    "    def calculate_recall(self, pred, target):\n",
    "        # CPU 사용하여 메모리 부담 감소\n",
    "        pred_flat = pred.view(-1).cpu().detach().numpy()\n",
    "        target_flat = target.view(-1).cpu().detach().numpy()\n",
    "\n",
    "        pred_binary = (pred_flat > 0.5).astype(np.int32)\n",
    "        target_binary = (target_flat > 0.5).astype(np.int32)\n",
    "\n",
    "        recall = recall_score(target_binary, pred_binary, zero_division=1)\n",
    "        return torch.tensor(recall)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "\n",
    "        # 스케줄러\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=3, verbose=True, min_lr=1e-6\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': scheduler,\n",
    "            'monitor': 'val_f1',\n",
    "            'interval': 'epoch'\n",
    "        }\n",
    "\n",
    "# 메모리 효율적인 예측 결과 시각화\n",
    "def visualize_predictions(model, test_loader, threshold=0.5, num_samples=3):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    plt.figure(figsize=(15, 5 * num_samples))\n",
    "\n",
    "    metrics = {\n",
    "        'f1_scores': [],\n",
    "        'precision_scores': [],\n",
    "        'recall_scores': []\n",
    "    }\n",
    "\n",
    "    for i, (images, masks) in enumerate(test_loader):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(images)\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "            pred_masks = (predictions > threshold).float()\n",
    "\n",
    "        # 메트릭 계산\n",
    "        pred_flat = pred_masks[0].cpu().flatten().numpy()\n",
    "        mask_flat = masks[0].cpu().flatten().numpy()\n",
    "\n",
    "        f1 = f1_score(mask_flat, pred_flat, zero_division=1)\n",
    "        precision = precision_score(mask_flat, pred_flat, zero_division=1)\n",
    "        recall = recall_score(mask_flat, pred_flat, zero_division=1)\n",
    "\n",
    "        metrics['f1_scores'].append(f1)\n",
    "        metrics['precision_scores'].append(precision)\n",
    "        metrics['recall_scores'].append(recall)\n",
    "\n",
    "        # CPU로 데이터 이동 및 넘파이 변환\n",
    "        images = images.cpu().numpy()\n",
    "        masks = masks.cpu().numpy()\n",
    "        pred_masks = pred_masks.cpu().numpy()\n",
    "\n",
    "        # 배치의 첫 번째 이미지만 표시\n",
    "        image = np.transpose(images[0], (1, 2, 0))\n",
    "        mask = masks[0, 0]\n",
    "        pred_mask = pred_masks[0, 0]\n",
    "\n",
    "        # 정규화 이미지 역변환\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "        # 시각화\n",
    "        plt.subplot(num_samples, 3, i*3 + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'이미지 {i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_samples, 3, i*3 + 2)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.title(f'실제 마스크 {i+1}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_samples, 3, i*3 + 3)\n",
    "        plt.imshow(pred_mask, cmap='gray')\n",
    "        plt.title(f'예측 마스크 {i+1}\\nF1: {f1:.4f}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 중간에 메모리 정리\n",
    "        clean_memory()\n",
    "\n",
    "    # 평균 메트릭 계산\n",
    "    avg_f1 = np.mean(metrics['f1_scores'])\n",
    "    avg_precision = np.mean(metrics['precision_scores'])\n",
    "    avg_recall = np.mean(metrics['recall_scores'])\n",
    "\n",
    "    plt.suptitle(f'평균 F1: {avg_f1:.4f}, 정밀도: {avg_precision:.4f}, 재현율: {avg_recall:.4f}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_results_lightweight_optimized.png')\n",
    "    plt.show()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# 간소화된 TTA(Test Time Augmentation) 함수\n",
    "def tta_predict(model, image):\n",
    "    model.eval()\n",
    "\n",
    "    # 원본 예측\n",
    "    with torch.no_grad():\n",
    "        pred_orig = torch.sigmoid(model(image))\n",
    "\n",
    "    # 수평 뒤집기\n",
    "    with torch.no_grad():\n",
    "        img_flip = torch.flip(image, [3])\n",
    "        pred_flip = torch.sigmoid(model(img_flip))\n",
    "        pred_flip = torch.flip(pred_flip, [3])\n",
    "\n",
    "    # 예측 결과 평균 \n",
    "    final_pred = (pred_orig + pred_flip) / 2.0\n",
    "    return final_pred\n",
    "\n",
    "# 메인 함수\n",
    "def main():\n",
    "    print(\"메모리 최적화된 뇌종양 세그멘테이션 - 경량화 모델 (5GB 미만 메모리 사용)\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # PyTorch 환경 확인 및 설정\n",
    "    print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "    \n",
    "    # GPU 상태 확인\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "        print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "        print(f\"CUDA 디바이스 이름: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU 총 메모리: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\")\n",
    "        \n",
    "        # GPU 디버깅 정보\n",
    "        device_count = torch.cuda.device_count()\n",
    "        print(f\"사용 가능한 GPU 개수: {device_count}\")\n",
    "        for i in range(device_count):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"GPU를 사용할 수 없습니다. CPU 모드로 실행됩니다.\")\n",
    "\n",
    "    # PyTorch 메모리 최적화 설정\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # 데이터 로더 생성 (배치 크기 감소)\n",
    "    batch_size = 2  # 메모리 사용량 감소를 위해 배치 크기 최소화\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(dataset, batch_size)\n",
    "    print(f\"데이터 로더 생성 완료! 훈련 샘플 수: {len(train_loader.dataset)}\")\n",
    "\n",
    "    # 모델 생성\n",
    "    print(\"경량화 모델 생성 중...\")\n",
    "    model = LightHRNetSegmentation(num_classes=1, lr=0.001, weight_decay=1e-4)\n",
    "    print(\"모델 생성 완료!\")\n",
    "    \n",
    "    # 모델 요약정보 출력\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"모델 총 파라미터 수: {total_params:,}\")\n",
    "    \n",
    "    # 체크포인트 저장 최소화\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_f1',\n",
    "        dirpath='checkpoints/',\n",
    "        filename='lightweight_brain_tumor-{epoch:02d}-{val_f1:.4f}',\n",
    "        save_top_k=1,  # 최고 성능 모델만 저장\n",
    "        mode='max',\n",
    "    )\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_f1',\n",
    "        patience=5,\n",
    "        mode='max',\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # PL 트레이너 설정 (수정됨)\n",
    "    print(\"트레이너 설정 중...\")\n",
    "    try:\n",
    "        # PyTorch Lightning 2.0 이상 버전\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=15,\n",
    "            accelerator='auto',  # 자동 감지\n",
    "            devices='auto' if torch.cuda.is_available() else None,\n",
    "            precision=16 if torch.cuda.is_available() else 32,\n",
    "            callbacks=[\n",
    "                checkpoint_callback,\n",
    "                early_stop_callback,\n",
    "                LearningRateMonitor(logging_interval='epoch')\n",
    "            ],\n",
    "            log_every_n_steps=20,\n",
    "            gradient_clip_val=1.0,\n",
    "            accumulate_grad_batches=4,\n",
    "            enable_checkpointing=True,\n",
    "            enable_progress_bar=True,\n",
    "            enable_model_summary=True,\n",
    "            deterministic=True,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"트레이너 초기화 오류: {e}\")\n",
    "        print(\"대체 설정으로 시도합니다...\")\n",
    "        \n",
    "        # 대체 설정 (이전 버전 호환)\n",
    "        try:\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=15,\n",
    "                gpus=1 if torch.cuda.is_available() else 0,  # 이전 버전 방식\n",
    "                precision=16 if torch.cuda.is_available() else 32,\n",
    "                callbacks=[\n",
    "                    checkpoint_callback,\n",
    "                    early_stop_callback,\n",
    "                    LearningRateMonitor(logging_interval='epoch')\n",
    "                ],\n",
    "                log_every_n_steps=20,\n",
    "                gradient_clip_val=1.0,\n",
    "                accumulate_grad_batches=4,\n",
    "                checkpoint_callback=True,\n",
    "                progress_bar_refresh_rate=10\n",
    "            )\n",
    "        except Exception as e2:\n",
    "            print(f\"대체 트레이너 초기화 오류: {e2}\")\n",
    "            print(\"최소 설정으로 시도합니다...\")\n",
    "            \n",
    "            # 최소 설정\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=15,\n",
    "                logger=False,\n",
    "                callbacks=[early_stop_callback]\n",
    "            )\n",
    "\n",
    "    # 현재 메모리 사용량 확인\n",
    "    print_gpu_memory()\n",
    "\n",
    "    # 메모리 정리\n",
    "    clean_memory()\n",
    "    \n",
    "    try:\n",
    "        # 모델 훈련\n",
    "        print(\"모델 훈련 시작...\")\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        print(\"훈련 완료!\")\n",
    "\n",
    "        # 최고 성능 출력\n",
    "        print(f\"최고 검증 F1 스코어: {model.best_val_f1:.4f}\")\n",
    "\n",
    "        # 메모리 정리\n",
    "        clean_memory()\n",
    "        \n",
    "        # 모델 테스트\n",
    "        print(\"모델 테스트 중...\")\n",
    "        test_results = trainer.test(model, test_loader)\n",
    "        print(f\"테스트 결과: {test_results}\")\n",
    "        \n",
    "        # 메모리 정리\n",
    "        clean_memory()\n",
    "\n",
    "        # 모델 저장\n",
    "        torch.save(model.state_dict(), 'lightweight_brain_tumor_optimized.pth')\n",
    "        print(\"모델 저장 완료: lightweight_brain_tumor_optimized.pth\")\n",
    "\n",
    "        # 메모리 정리\n",
    "        clean_memory()\n",
    "        \n",
    "        # 예측 결과 시각화\n",
    "        print(\"예측 결과 시각화 중...\")\n",
    "        metrics = visualize_predictions(model, test_loader, threshold=0.5, num_samples=3)\n",
    "        print(f\"테스트 세트의 평균 F1 스코어: {np.mean(metrics['f1_scores']):.4f}\")\n",
    "        \n",
    "        print(\"완료!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(\"\\nGPU 메모리 부족 오류가 발생했습니다.\")\n",
    "            print(\"다음 단계를 시도해 보세요:\\n\")\n",
    "            print(\"1. 배치 크기를 1로 줄이기\")\n",
    "            print(\"2. 이미지 크기를 128 또는 96으로 줄이기\")\n",
    "            print(\"3. 더 작은 모델(ResNet18) 사용하기\")\n",
    "            print(\"4. 데이터셋 크기 제한하기 (코드에서 주석 해제)\")\n",
    "            print(\"5. torch.cuda.set_per_process_memory_fraction() 값을 0.4로 낮추기\\n\")\n",
    "        \n",
    "    finally:\n",
    "        # 최종 메모리 정리\n",
    "        clean_memory()\n",
    "        print(\"최종 메모리 사용량:\")\n",
    "        print_gpu_memory()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 디버그 정보 출력\n",
    "    print(\"\\n==== GPU 디버그 정보 ====\")\n",
    "    print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA 디바이스 수: {torch.cuda.device_count()}\")\n",
    "        print(f\"현재 디바이스: {torch.cuda.current_device()}\")\n",
    "        print(f\"디바이스 이름: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\"=======================\\n\")\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a65afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
