{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets pytorch-lightning segmentation-models-pytorch albumentations timm\n",
        "!pip install -q datasets pytorch-lightning albumentations timm\n",
        "!mkdir -p checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WlSqz8qi4y0",
        "outputId": "3b0e226d-348e-489f-c655-18dae6805fba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/823.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from albumentations import Compose, Resize, Normalize\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import timm\n",
        "import warnings"
      ],
      "metadata": {
        "id": "FEjrwvhPAhzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trHwjWtTeUom"
      },
      "outputs": [],
      "source": [
        "# HRNet-W30-C 뇌종양 세그멘테이션 모델 (F1 Score 최적화)\n",
        "# 필요한 라이브러리 설치\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 랜덤 시드 설정\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# 데이터셋 로드\n",
        "print(\"데이터셋 로드 중...\")\n",
        "dataset = load_dataset(\"dwb2023/brain-tumor-image-dataset-semantic-segmentation\")\n",
        "print(\"데이터셋 로드 완료!\")\n",
        "\n",
        "# 데이터셋 구조 확인\n",
        "print(\"데이터셋 구조:\")\n",
        "print(dataset)\n",
        "\n",
        "# 데이터 전처리 및 증강\n",
        "class BrainTumorDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, split='train', img_size=224):\n",
        "        self.dataset = hf_dataset[split]\n",
        "        self.img_size = img_size\n",
        "        self.split = split\n",
        "        self.transform = self.get_transforms(split)\n",
        "\n",
        "    def get_transforms(self, split):\n",
        "        # 기본 전처리만 적용\n",
        "        return Compose([\n",
        "            Resize(self.img_size, self.img_size),\n",
        "            Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "    def create_mask_from_segmentation(self, segmentation, height, width):\n",
        "        # segmentation (다각형 좌표)에서 마스크 생성\n",
        "        mask = np.zeros((height, width), dtype=np.float32)\n",
        "\n",
        "        if segmentation and isinstance(segmentation, list):\n",
        "            for polygon in segmentation:\n",
        "                if len(polygon) > 4:  # 최소 3개의 좌표(x,y) 쌍이 필요\n",
        "                    # [x1, y1, x2, y2, ...] 형식을 (N, 2) 형식으로 변환\n",
        "                    points = np.array(polygon).reshape(-1, 2).astype(np.int32)\n",
        "                    cv2.fillPoly(mask, [points], 1)\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        image = np.array(item['image'])\n",
        "        height, width = image.shape[:2]\n",
        "\n",
        "        # segmentation에서 마스크 생성\n",
        "        mask = self.create_mask_from_segmentation(item['segmentation'], height, width)\n",
        "\n",
        "        # 이미지 및 마스크 전처리\n",
        "        transformed = self.transform(image=image, mask=mask)\n",
        "        image = transformed['image']\n",
        "        mask = transformed['mask'].unsqueeze(0)  # 채널 차원 추가 [1, H, W]\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# 데이터 로더 생성\n",
        "def create_dataloaders(dataset, batch_size=8):\n",
        "    train_dataset = BrainTumorDataset(dataset, 'train')\n",
        "    val_dataset = BrainTumorDataset(dataset, 'valid')\n",
        "    test_dataset = BrainTumorDataset(dataset, 'test')\n",
        "\n",
        "    # num_workers 증가 및 핀 메모리 활성화\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                             num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                           num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# Dice 손실 함수 정의\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.0):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred = torch.sigmoid(y_pred)\n",
        "\n",
        "        # 분자 (intersection)\n",
        "        intersection = torch.sum(y_true * y_pred)\n",
        "\n",
        "        # 분모 (union)\n",
        "        union = torch.sum(y_true) + torch.sum(y_pred)\n",
        "\n",
        "        # Dice 계수\n",
        "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
        "\n",
        "        return 1.0 - dice  # 최소화를 위해 1에서 빼기\n",
        "\n",
        "# F1 손실 함수\n",
        "class F1Loss(nn.Module):\n",
        "    def __init__(self, epsilon=1e-7):\n",
        "        super(F1Loss, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred = torch.sigmoid(y_pred)\n",
        "\n",
        "        tp = torch.sum(y_true * y_pred)\n",
        "        fp = torch.sum((1 - y_true) * y_pred)\n",
        "        fn = torch.sum(y_true * (1 - y_pred))\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "\n",
        "        f1 = 2 * precision * recall / (precision + recall + self.epsilon)\n",
        "\n",
        "        return 1 - f1  # 최소화를 위해 1에서 빼기\n",
        "\n",
        "# 조합 손실 함수\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, weights=(0.6, 0.4), smooth=1.0, alpha=0.7, beta=0.3):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.dice_loss = DiceLoss(smooth=smooth)\n",
        "        self.f1_loss = F1Loss()\n",
        "        self.weights = weights\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.focal_loss = FocalLoss(alpha=self.alpha, beta=self.beta)\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        dice = self.dice_loss(y_pred, y_true)\n",
        "        f1 = self.f1_loss(y_pred, y_true)\n",
        "        focal = self.focal_loss(y_pred, y_true)\n",
        "\n",
        "        return self.weights[0] * dice + self.weights[1] * (f1 + focal)\n",
        "\n",
        "# 포컬 손실 추가 (클래스 불균형 처리에 도움)\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7, beta=0.3, gamma=2.0):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_pred = torch.sigmoid(y_pred)\n",
        "\n",
        "        # 포지티브 샘플에 대한 포컬 손실\n",
        "        pos_loss = -self.alpha * (1 - y_pred) ** self.gamma * y_true * torch.log(y_pred + 1e-7)\n",
        "\n",
        "        # 네거티브 샘플에 대한 포컬 손실\n",
        "        neg_loss = -self.beta * y_pred ** self.gamma * (1 - y_true) * torch.log(1 - y_pred + 1e-7)\n",
        "\n",
        "        loss = pos_loss + neg_loss\n",
        "        return loss.mean()\n",
        "\n",
        "# 세그멘테이션 헤드 정의\n",
        "class SegmentationHead(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(SegmentationHead, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "# HRNet-W30-C 세그멘테이션 모델\n",
        "class HRNetW30Segmentation(pl.LightningModule):\n",
        "    def __init__(self, num_classes=1, lr=0.0005, weight_decay=1e-4):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.num_classes = num_classes\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "\n",
        "        # 향상된 손실 함수 가중치\n",
        "        self.criterion = CombinedLoss(weights=(0.6, 0.4))\n",
        "\n",
        "        # 성능 메트릭 저장\n",
        "        self.best_val_f1 = 0.0\n",
        "\n",
        "        # HRNet-W30-C 백본 로드\n",
        "        self.backbone = timm.create_model(\n",
        "            'hrnet_w30',\n",
        "            pretrained=True,\n",
        "            features_only=True\n",
        "        )\n",
        "\n",
        "        # 마지막 특성 맵의 채널 수\n",
        "        last_channels = self.backbone.feature_info[-1]['num_chs']\n",
        "\n",
        "        # 향상된 세그멘테이션 헤드 (더 복잡한 구조로 변경)\n",
        "        self.segmentation_head = nn.Sequential(\n",
        "            nn.Conv2d(last_channels, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, num_classes, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 입력 크기 저장\n",
        "        input_size = x.shape[2:]\n",
        "\n",
        "        # 백본으로 특성 추출\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        # 마지막 특성 맵 사용\n",
        "        last_feature = features[-1]\n",
        "\n",
        "        # 세그멘테이션 헤드 통과\n",
        "        logits = self.segmentation_head(last_feature)\n",
        "\n",
        "        # 원래 이미지 크기로 업샘플링\n",
        "        if logits.shape[2:] != input_size:\n",
        "            logits = F.interpolate(logits, size=input_size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, masks = batch\n",
        "        predictions = self(images)\n",
        "        loss = self.criterion(predictions, masks)\n",
        "\n",
        "        # F1 스코어 계산\n",
        "        pred_masks = (torch.sigmoid(predictions) > 0.5).float()\n",
        "        f1 = self.calculate_f1_score(pred_masks, masks)\n",
        "        precision = self.calculate_precision(pred_masks, masks)\n",
        "        recall = self.calculate_recall(pred_masks, masks)\n",
        "\n",
        "        # 로깅\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.log('train_f1', f1, prog_bar=True)\n",
        "        self.log('train_precision', precision, prog_bar=False)\n",
        "        self.log('train_recall', recall, prog_bar=False)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, masks = batch\n",
        "        predictions = self(images)\n",
        "        loss = self.criterion(predictions, masks)\n",
        "\n",
        "        # F1 스코어 계산\n",
        "        pred_masks = (torch.sigmoid(predictions) > 0.5).float()\n",
        "        f1 = self.calculate_f1_score(pred_masks, masks)\n",
        "        precision = self.calculate_precision(pred_masks, masks)\n",
        "        recall = self.calculate_recall(pred_masks, masks)\n",
        "        iou = self.calculate_iou(pred_masks, masks)\n",
        "\n",
        "        # 로깅\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_f1', f1, prog_bar=True)\n",
        "        self.log('val_precision', precision, prog_bar=True)\n",
        "        self.log('val_recall', recall, prog_bar=True)\n",
        "        self.log('val_iou', iou, prog_bar=False)\n",
        "\n",
        "        # 최고 F1 스코어 업데이트\n",
        "        if f1 > self.best_val_f1:\n",
        "            self.best_val_f1 = f1\n",
        "\n",
        "        return {'val_loss': loss, 'val_f1': f1}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        images, masks = batch\n",
        "        predictions = self(images)\n",
        "\n",
        "        # F1 스코어 계산\n",
        "        pred_masks = (torch.sigmoid(predictions) > 0.5).float()\n",
        "        f1 = self.calculate_f1_score(pred_masks, masks)\n",
        "        precision = self.calculate_precision(pred_masks, masks)\n",
        "        recall = self.calculate_recall(pred_masks, masks)\n",
        "        iou = self.calculate_iou(pred_masks, masks)\n",
        "\n",
        "        # 로깅\n",
        "        self.log('test_f1', f1)\n",
        "        self.log('test_precision', precision)\n",
        "        self.log('test_recall', recall)\n",
        "        self.log('test_iou', iou)\n",
        "\n",
        "        return {'test_f1': f1, 'test_precision': precision, 'test_recall': recall}\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        images, _ = batch\n",
        "        predictions = self(images)\n",
        "        pred_masks = (torch.sigmoid(predictions) > 0.5).float()\n",
        "        return pred_masks\n",
        "\n",
        "    def calculate_f1_score(self, pred, target):\n",
        "        # 배치 처리\n",
        "        pred_flat = pred.view(-1).cpu().detach().numpy()\n",
        "        target_flat = target.view(-1).cpu().detach().numpy()\n",
        "\n",
        "        # 예측값이 0.5보다 크면 1, 아니면 0\n",
        "        pred_binary = (pred_flat > 0.5).astype(np.int32)\n",
        "        target_binary = (target_flat > 0.5).astype(np.int32)\n",
        "\n",
        "        # F1 스코어 계산\n",
        "        f1 = f1_score(target_binary, pred_binary, zero_division=1)\n",
        "        return torch.tensor(f1)\n",
        "\n",
        "    def calculate_precision(self, pred, target):\n",
        "        # 배치 처리\n",
        "        pred_flat = pred.view(-1).cpu().detach().numpy()\n",
        "        target_flat = target.view(-1).cpu().detach().numpy()\n",
        "\n",
        "        # 예측값이 0.5보다 크면 1, 아니면 0\n",
        "        pred_binary = (pred_flat > 0.5).astype(np.int32)\n",
        "        target_binary = (target_flat > 0.5).astype(np.int32)\n",
        "\n",
        "        # 정밀도 계산\n",
        "        precision = precision_score(target_binary, pred_binary, zero_division=1)\n",
        "        return torch.tensor(precision)\n",
        "\n",
        "    def calculate_recall(self, pred, target):\n",
        "        # 배치 처리\n",
        "        pred_flat = pred.view(-1).cpu().detach().numpy()\n",
        "        target_flat = target.view(-1).cpu().detach().numpy()\n",
        "\n",
        "        # 예측값이 0.5보다 크면 1, 아니면 0\n",
        "        pred_binary = (pred_flat > 0.5).astype(np.int32)\n",
        "        target_binary = (target_flat > 0.5).astype(np.int32)\n",
        "\n",
        "        # 재현율 계산\n",
        "        recall = recall_score(target_binary, pred_binary, zero_division=1)\n",
        "        return torch.tensor(recall)\n",
        "\n",
        "    def calculate_iou(self, pred, target):\n",
        "        # Intersection over Union 계산\n",
        "        intersection = (pred * target).sum(dim=(1, 2, 3))\n",
        "        union = pred.sum(dim=(1, 2, 3)) + target.sum(dim=(1, 2, 3)) - intersection\n",
        "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "        return iou.mean()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            self.parameters(),\n",
        "            lr=self.lr,\n",
        "            weight_decay=self.weight_decay\n",
        "        )\n",
        "\n",
        "        # 개선된 스케줄러 전략\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='max', factor=0.75, patience=2, verbose=True, min_lr=1e-6\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': scheduler,\n",
        "            'monitor': 'val_f1',\n",
        "            'interval': 'epoch'\n",
        "        }\n",
        "\n",
        "# 최적의 임계값 찾기\n",
        "def find_optimal_threshold(model, val_loader):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    all_preds = []\n",
        "    all_masks = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            preds = model(images)\n",
        "            preds = torch.sigmoid(preds)\n",
        "\n",
        "            all_preds.append(preds.cpu().numpy())\n",
        "            all_masks.append(masks.cpu().numpy())\n",
        "\n",
        "    all_preds = np.concatenate([p.flatten() for p in all_preds])\n",
        "    all_masks = np.concatenate([m.flatten() for m in all_masks])\n",
        "\n",
        "    # 다양한 임계값에 대한 F1 스코어 계산\n",
        "    thresholds = np.arange(0.2, 0.7, 0.02)\n",
        "    f1_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        pred_binary = (all_preds > threshold).astype(np.int32)\n",
        "        target_binary = (all_masks > 0.5).astype(np.int32)\n",
        "\n",
        "        f1 = f1_score(target_binary, pred_binary)\n",
        "        precision = precision_score(target_binary, pred_binary, zero_division=1)\n",
        "        recall = recall_score(target_binary, pred_binary, zero_division=1)\n",
        "\n",
        "        f1_scores.append(f1)\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "\n",
        "    # 최적의 임계값 찾기\n",
        "    best_idx = np.argmax(f1_scores)\n",
        "    best_threshold = thresholds[best_idx]\n",
        "    best_f1 = f1_scores[best_idx]\n",
        "    best_precision = precision_scores[best_idx]\n",
        "    best_recall = recall_scores[best_idx]\n",
        "\n",
        "    print(f\"최적의 임계값: {best_threshold:.2f}\")\n",
        "    print(f\"F1 스코어: {best_f1:.4f}, 정밀도: {best_precision:.4f}, 재현율: {best_recall:.4f}\")\n",
        "\n",
        "    # 임계값 별 F1 스코어 시각화\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(thresholds, f1_scores, 'o-', label='F1 Score')\n",
        "    plt.plot(thresholds, precision_scores, 's-', label='Precision')\n",
        "    plt.plot(thresholds, recall_scores, '^-', label='Recall')\n",
        "    plt.axvline(x=best_threshold, color='r', linestyle='--', label=f'최적 임계값: {best_threshold:.2f}')\n",
        "    plt.xlabel('임계값')\n",
        "    plt.ylabel('점수')\n",
        "    plt.title('임계값에 따른 성능 변화')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.savefig('threshold_performance.png')\n",
        "    plt.show()\n",
        "\n",
        "    return best_threshold\n",
        "\n",
        "# 예측 결과 시각화\n",
        "def visualize_predictions(model, test_loader, threshold=0.5, num_samples=5):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    plt.figure(figsize=(15, 5 * num_samples))\n",
        "\n",
        "    metrics = {\n",
        "        'f1_scores': [],\n",
        "        'precision_scores': [],\n",
        "        'recall_scores': []\n",
        "    }\n",
        "\n",
        "    for i, (images, masks) in enumerate(test_loader):\n",
        "        if i >= num_samples:\n",
        "            break\n",
        "\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = model(images)\n",
        "            predictions = torch.sigmoid(predictions)\n",
        "            pred_masks = (predictions > threshold).float()\n",
        "\n",
        "        # 메트릭 계산\n",
        "        pred_flat = pred_masks[0].cpu().flatten().numpy()\n",
        "        mask_flat = masks[0].cpu().flatten().numpy()\n",
        "\n",
        "        f1 = f1_score(mask_flat, pred_flat, zero_division=1)\n",
        "        precision = precision_score(mask_flat, pred_flat, zero_division=1)\n",
        "        recall = recall_score(mask_flat, pred_flat, zero_division=1)\n",
        "\n",
        "        metrics['f1_scores'].append(f1)\n",
        "        metrics['precision_scores'].append(precision)\n",
        "        metrics['recall_scores'].append(recall)\n",
        "\n",
        "        # CPU로 데이터 이동 및 넘파이 변환\n",
        "        images = images.cpu().numpy()\n",
        "        masks = masks.cpu().numpy()\n",
        "        pred_masks = pred_masks.cpu().numpy()\n",
        "\n",
        "        # 배치의 첫 번째 이미지만 표시\n",
        "        image = np.transpose(images[0], (1, 2, 0))\n",
        "        mask = masks[0, 0]\n",
        "        pred_mask = pred_masks[0, 0]\n",
        "\n",
        "        # 정규화 이미지 역변환\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "        # 시각화\n",
        "        plt.subplot(num_samples, 3, i*3 + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(f'이미지 {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples, 3, i*3 + 2)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title(f'실제 마스크 {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(num_samples, 3, i*3 + 3)\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "        plt.title(f'예측 마스크 {i+1}\\nF1: {f1:.4f}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    # 평균 메트릭 계산\n",
        "    avg_f1 = np.mean(metrics['f1_scores'])\n",
        "    avg_precision = np.mean(metrics['precision_scores'])\n",
        "    avg_recall = np.mean(metrics['recall_scores'])\n",
        "\n",
        "    plt.suptitle(f'평균 F1: {avg_f1:.4f}, 정밀도: {avg_precision:.4f}, 재현율: {avg_recall:.4f}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('prediction_results.png')\n",
        "    plt.show()\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# 메인 함수\n",
        "def main():\n",
        "    print(\"뇌종양 세그멘테이션 - HRNet-W30-C (F1 Score 최적화)\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Google Colab 환경 확인\n",
        "    print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "    print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA 디바이스 이름: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "    # PyTorch 병렬 처리 최적화 설정\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "    # 데이터 로더 생성 (배치 크기 증가)\n",
        "    batch_size = 8  # 배치 크기 증가\n",
        "    train_loader, val_loader, test_loader = create_dataloaders(dataset, batch_size)\n",
        "    print(f\"데이터 로더 생성 완료! 훈련 샘플 수: {len(train_loader.dataset)}\")\n",
        "\n",
        "    # 모델 생성 (개선된 파라미터)\n",
        "    print(\"HRNet-W30-C 모델 생성 중...\")\n",
        "    model = HRNetW30Segmentation(num_classes=1, lr=0.0005, weight_decay=1e-4)\n",
        "    print(\"모델 생성 완료!\")\n",
        "\n",
        "    # 콜백 설정\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        monitor='val_f1',\n",
        "        dirpath='checkpoints/',\n",
        "        filename='hrnet_w30_brain_tumor-{epoch:02d}-{val_f1:.4f}',\n",
        "        save_top_k=3,\n",
        "        mode='max',\n",
        "    )\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "        monitor='val_f1',\n",
        "        patience=7,\n",
        "        mode='max',\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    # 트레이너 설정 (최적화된 설정)\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=30,\n",
        "        accelerator='gpu',\n",
        "        devices=1,\n",
        "        precision=16,  # 혼합 정밀도 훈련\n",
        "        callbacks=[\n",
        "            checkpoint_callback,\n",
        "            early_stop_callback,\n",
        "            LearningRateMonitor(logging_interval='epoch')\n",
        "        ],\n",
        "        log_every_n_steps=10,\n",
        "        gradient_clip_val=1.0,  # 그래디언트 클리핑\n",
        "    )\n",
        "\n",
        "    # 모델 훈련\n",
        "    print(\"모델 훈련 시작...\")\n",
        "    trainer.fit(model, train_loader, val_loader)\n",
        "    print(\"훈련 완료!\")\n",
        "\n",
        "    # 최고 성능 출력\n",
        "    print(f\"최고 검증 F1 스코어: {model.best_val_f1:.4f}\")\n",
        "\n",
        "    # 모델 테스트\n",
        "    print(\"모델 테스트 중...\")\n",
        "    test_results = trainer.test(model, test_loader)\n",
        "    print(f\"테스트 결과: {test_results}\")\n",
        "\n",
        "    # 최적의 임계값 찾기\n",
        "    best_threshold = find_optimal_threshold(model, val_loader)\n",
        "\n",
        "    # 모델 저장\n",
        "    torch.save(model.state_dict(), 'hrnet_w30_brain_tumor_f1_optimized.pth')\n",
        "    print(\"모델 저장 완료: hrnet_w30_brain_tumor_f1_optimized.pth\")\n",
        "\n",
        "    # 예측 결과 시각화\n",
        "    print(\"예측 결과 시각화 중...\")\n",
        "    metrics = visualize_predictions(model, test_loader, threshold=best_threshold)\n",
        "    print(f\"테스트 세트의 평균 F1 스코어: {np.mean(metrics['f1_scores']):.4f}\")\n",
        "    print(f\"테스트 세트의 평균 정밀도: {np.mean(metrics['precision_scores']):.4f}\")\n",
        "    print(f\"테스트 세트의 평균 재현율: {np.mean(metrics['recall_scores']):.4f}\")\n",
        "\n",
        "    print(\"완료!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}