{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124b4ab2",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c074f88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (4.67.1)\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-2.0.6-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: pillow in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (2.2.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: packaging in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: colorama in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from albumentations) (1.15.2)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Using cached pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Using cached albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\githubrepo\\neuraseg-hrnet-high-resolution-mri-brain-tumor-detection-and-segmentation\\.venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Using cached albumentations-2.0.6-py3-none-any.whl (332 kB)\n",
      "Using cached albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "Using cached pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: opencv-python-headless, annotated-types, pydantic, albucore, albumentations\n",
      "\n",
      "   ---------------------------------------- 0/5 [opencv-python-headless]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] 액세스가 거부되었습니다: 'c:\\\\GitHubRepo\\\\NeuraSeg-HRNet-High-Resolution-MRI-Brain-Tumor-Detection-and-Segmentation\\\\.venv\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install datasets tqdm albumentations opencv-python matplotlib pillow huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fcc574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 디렉토리 설정 중...\n",
      "기존 폴더 삭제 중: ./augmented_data\n",
      "디렉토리 생성 완료: ./augmented_data\\train\n",
      "디렉토리 생성 완료: ./augmented_data\\test\n",
      "디렉토리 생성 완료: ./augmented_data\\valid\n",
      "허깅페이스에서 데이터셋 로드 중...\n",
      "데이터셋 로드 완료!\n",
      "\n",
      "===== TRAIN 데이터셋 준비 시작 =====\n",
      "train 데이터셋 크기: 1502 이미지\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 데이터 준비: 100%|██████████| 1502/1502 [00:05<00:00, 272.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터셋 준비 완료: 1502 이미지\n",
      "\n",
      "===== TEST 데이터셋 준비 시작 =====\n",
      "test 데이터셋 크기: 215 이미지\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 데이터 준비: 100%|██████████| 215/215 [00:00<00:00, 247.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 데이터셋 준비 완료: 215 이미지\n",
      "\n",
      "===== VALID 데이터셋 준비 시작 =====\n",
      "valid 데이터셋 크기: 429 이미지\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 데이터 준비: 100%|██████████| 429/429 [00:02<00:00, 208.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid 데이터셋 준비 완료: 429 이미지\n",
      "\n",
      "===== TRAIN 데이터셋 증강 시작 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 이미지 증강 중:   0%|          | 0/1502 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_0_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_0_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_0_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 이미지 증강 중:   0%|          | 1/1502 [00:02<58:04,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_0_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_1_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_1_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_1_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 이미지 증강 중:   0%|          | 2/1502 [00:04<56:20,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_1_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_2_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_2_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_2_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 이미지 증강 중:   0%|          | 3/1502 [00:06<53:05,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_2_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_3_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_3_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_3_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 이미지 증강 중:   0%|          | 4/1502 [00:08<51:33,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_3_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_4_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_4_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_4_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 이미지 증강 중:   2%|▏         | 31/1502 [00:10<03:48,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\train_4_좌우_뒤집기.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 이미지 증강 중: 100%|██████████| 1502/1502 [00:15<00:00, 97.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터셋 증강 완료: 원본 1502개, 증강 6008개, 총 7510개\n",
      "\n",
      "===== TEST 데이터셋 증강 시작 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 이미지 증강 중:   0%|          | 0/215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_0_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_0_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_0_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 이미지 증강 중:   0%|          | 1/215 [00:02<07:40,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_0_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_1_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_1_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_1_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 이미지 증강 중:   1%|          | 2/215 [00:04<07:06,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_1_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_2_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_2_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_2_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 이미지 증강 중:   1%|▏         | 3/215 [00:05<06:52,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_2_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_3_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_3_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_3_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 이미지 증강 중:   2%|▏         | 4/215 [00:07<06:28,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_3_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_4_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_4_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_4_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 이미지 증강 중:  20%|█▉        | 42/215 [00:09<00:16, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\test_4_좌우_뒤집기.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 이미지 증강 중: 100%|██████████| 215/215 [00:10<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 데이터셋 증강 완료: 원본 215개, 증강 860개, 총 1075개\n",
      "\n",
      "===== VALID 데이터셋 증강 시작 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 이미지 증강 중:   0%|          | 0/429 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_0_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_0_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_0_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 이미지 증강 중:   0%|          | 1/429 [00:01<10:52,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_0_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_1_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_1_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_1_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 이미지 증강 중:   0%|          | 2/429 [00:03<11:01,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_1_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_2_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_2_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_2_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 이미지 증강 중:   1%|          | 3/429 [00:04<11:23,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_2_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_3_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_3_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_3_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 이미지 증강 중:   1%|          | 4/429 [00:06<12:29,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_3_좌우_뒤집기.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_4_90도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_4_180도_회전.png\n",
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_4_270도_회전.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 이미지 증강 중:  10%|█         | 44/429 [00:08<00:33, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 결과 저장: ./augmented_data\\visualizations\\valid_4_좌우_뒤집기.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 이미지 증강 중: 100%|██████████| 429/429 [00:09<00:00, 44.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid 데이터셋 증강 완료: 원본 429개, 증강 1716개, 총 2145개\n",
      "\n",
      "===== 모든 데이터를 디스크에 저장 중 =====\n",
      "\n",
      "TRAIN 이미지 저장 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 이미지 저장: 100%|██████████| 7505/7505 [04:15<00:00, 29.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST 이미지 저장 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 이미지 저장: 100%|██████████| 1075/1075 [00:34<00:00, 30.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID 이미지 저장 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 이미지 저장: 100%|██████████| 2145/2145 [01:08<00:00, 31.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 어노테이션 저장 완료: ./augmented_data\\train_annotations.json (7510개)\n",
      "test 어노테이션 저장 완료: ./augmented_data\\test_annotations.json (1075개)\n",
      "valid 어노테이션 저장 완료: ./augmented_data\\valid_annotations.json (2145개)\n",
      "\n",
      "===== 데이터 저장 결과 =====\n",
      "train: 성공 7505개, 오류 0개\n",
      "test: 성공 1075개, 오류 0개\n",
      "valid: 성공 2145개, 오류 0개\n",
      "\n",
      "===== 허깅페이스 데이터셋 생성 중 =====\n",
      "\n",
      "TRAIN 데이터셋 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 데이터셋 생성: 100%|██████████| 7510/7510 [00:38<00:00, 194.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터셋 생성 완료: 7510 샘플\n",
      "\n",
      "TEST 데이터셋 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test 데이터셋 생성: 100%|██████████| 1075/1075 [00:05<00:00, 207.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 데이터셋 생성 완료: 1075 샘플\n",
      "\n",
      "VALID 데이터셋 처리 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "valid 데이터셋 생성: 100%|██████████| 2145/2145 [00:09<00:00, 223.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid 데이터셋 생성 완료: 2145 샘플\n",
      "\n",
      "허깅페이스에 데이터셋 업로드 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1878/1878 [00:01<00:00, 1088.03 examples/s]s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 19/19 [00:01<00:00, 16.12ba/s]\n",
      "Map: 100%|██████████| 1878/1878 [00:01<00:00, 1092.28 examples/s]48.93s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 19/19 [00:00<00:00, 20.06ba/s]\n",
      "Map: 100%|██████████| 1877/1877 [00:01<00:00, 1159.44 examples/s]46.93s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 19/19 [00:00<00:00, 22.19ba/s]\n",
      "Map: 100%|██████████| 1877/1877 [00:01<00:00, 1199.75 examples/s]45.81s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 19/19 [00:00<00:00, 22.49ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 4/4 [03:04<00:00, 46.15s/it]\n",
      "Map: 100%|██████████| 1075/1075 [00:00<00:00, 1233.77 examples/s]s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 11/11 [00:00<00:00, 24.03ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:25<00:00, 25.90s/it]\n",
      "Map: 100%|██████████| 2145/2145 [00:01<00:00, 1327.05 examples/s]s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 22/22 [00:01<00:00, 20.74ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:50<00:00, 50.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 업로드 완료!\n",
      "\n",
      "===== 업로드된 데이터셋 요약 =====\n",
      "train: 7510 샘플\n",
      "test: 1075 샘플\n",
      "valid: 2145 샘플\n",
      "총 샘플 수: 10730\n",
      "\n",
      "총 처리 시간: 729.66초 (12.16분)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, Dataset, Features, Value, Sequence, Image, DatasetDict\n",
    "from tqdm import tqdm\n",
    "from PIL import Image as PILImage\n",
    "from datetime import datetime\n",
    "from huggingface_hub import login\n",
    "import warnings\n",
    "import traceback\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 허깅페이스 로그인 토큰 (실제 사용 시 수정 필요)\n",
    "HF_TOKEN = \"\"  # 예시 토큰\n",
    "\n",
    "# 결과 저장 경로\n",
    "OUTPUT_PATH = \"./augmented_data\"\n",
    "SPLITS = ['train', 'test', 'valid']\n",
    "\n",
    "# 이미지와 어노테이션 저장 경로\n",
    "OUTPUT_IMAGES_PATH = {split: os.path.join(OUTPUT_PATH, split) for split in SPLITS}\n",
    "OUTPUT_ANNOTATIONS_FILE = {split: os.path.join(OUTPUT_PATH, f\"{split}_annotations.json\") for split in SPLITS}\n",
    "\n",
    "# 주요 문제 해결 - 모든 데이터를 메모리에 저장한 후 한번에 처리하는 방식으로 변경\n",
    "all_images = {split: {} for split in SPLITS}  # 원본 및 증강 이미지 저장\n",
    "all_annotations = {split: [] for split in SPLITS}  # 어노테이션 저장\n",
    "\n",
    "# 출력 디렉토리 초기화 및 생성\n",
    "def setup_directories():\n",
    "    \"\"\"\n",
    "    출력 디렉토리 초기화 및 생성\n",
    "    \"\"\"\n",
    "    print(\"출력 디렉토리 설정 중...\")\n",
    "    try:\n",
    "        # 기존 폴더가 있으면 삭제 (완전히 초기화)\n",
    "        if os.path.exists(OUTPUT_PATH):\n",
    "            print(f\"기존 폴더 삭제 중: {OUTPUT_PATH}\")\n",
    "            shutil.rmtree(OUTPUT_PATH)\n",
    "            time.sleep(1)  # 삭제 완료 대기\n",
    "        \n",
    "        # 새 폴더 생성\n",
    "        os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "        for split in SPLITS:\n",
    "            split_path = OUTPUT_IMAGES_PATH[split]\n",
    "            os.makedirs(split_path, exist_ok=True)\n",
    "            print(f\"디렉토리 생성 완료: {split_path}\")\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"디렉토리 설정 오류: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def load_dataset_from_huggingface():\n",
    "    \"\"\"\n",
    "    허깅페이스에서 데이터셋 로드\n",
    "    \"\"\"\n",
    "    print(\"허깅페이스에서 데이터셋 로드 중...\")\n",
    "    try:\n",
    "        dataset = load_dataset(\"dwb2023/brain-tumor-image-dataset-semantic-segmentation\")\n",
    "        print(\"데이터셋 로드 완료!\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f\"데이터셋 로드 오류: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "def calculate_area_from_mask(mask):\n",
    "    \"\"\"\n",
    "    마스크로부터 면적 계산\n",
    "    \"\"\"\n",
    "    return float(np.sum(mask))\n",
    "\n",
    "def create_mask_from_polygon(polygon, image_shape):\n",
    "    \"\"\"\n",
    "    다각형 좌표로부터 마스크 생성\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mask = np.zeros(image_shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        if not polygon:\n",
    "            return mask\n",
    "        \n",
    "        # 다각형 좌표 변환\n",
    "        polygon_points = []\n",
    "        for i in range(0, len(polygon), 2):\n",
    "            polygon_points.append([int(polygon[i]), int(polygon[i+1])])\n",
    "        \n",
    "        polygon_array = np.array([polygon_points], dtype=np.int32)\n",
    "        \n",
    "        # 다각형 내부를 채우기\n",
    "        cv2.fillPoly(mask, polygon_array, 1)\n",
    "        \n",
    "        return mask\n",
    "    except Exception as e:\n",
    "        print(f\"마스크 생성 오류: {str(e)}\")\n",
    "        return np.zeros(image_shape[:2], dtype=np.uint8)\n",
    "\n",
    "def calculate_bbox_from_mask(mask):\n",
    "    \"\"\"\n",
    "    마스크로부터 바운딩 박스 계산\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 마스크에서 0이 아닌 값의 좌표 찾기\n",
    "        rows = np.any(mask, axis=1)\n",
    "        cols = np.any(mask, axis=0)\n",
    "        \n",
    "        if not np.any(rows) or not np.any(cols):\n",
    "            return [0.0, 0.0, 0.0, 0.0]\n",
    "        \n",
    "        # 경계 좌표 찾기\n",
    "        y_min, y_max = np.where(rows)[0][[0, -1]]\n",
    "        x_min, x_max = np.where(cols)[0][[0, -1]]\n",
    "        \n",
    "        # [x_min, y_min, x_max, y_max] 형식으로 반환\n",
    "        return [float(x_min), float(y_min), float(x_max), float(y_max)]\n",
    "    except Exception as e:\n",
    "        print(f\"바운딩 박스 계산 오류: {str(e)}\")\n",
    "        return [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "# 이미지 회전 및 뒤집기 함수\n",
    "def rotate_image_90(image):\n",
    "    \"\"\"이미지를 90도 회전\"\"\"\n",
    "    return np.rot90(image, k=1) if image is not None else None\n",
    "\n",
    "def rotate_image_180(image):\n",
    "    \"\"\"이미지를 180도 회전\"\"\"\n",
    "    return np.rot90(image, k=2) if image is not None else None\n",
    "\n",
    "def rotate_image_270(image):\n",
    "    \"\"\"이미지를 270도 회전\"\"\"\n",
    "    return np.rot90(image, k=3) if image is not None else None\n",
    "\n",
    "def flip_image_horizontal(image):\n",
    "    \"\"\"이미지를 좌우 뒤집기\"\"\"\n",
    "    return np.fliplr(image) if image is not None else None\n",
    "\n",
    "def rotate_mask_90(mask, k=1):\n",
    "    \"\"\"마스크를 90도 회전\"\"\"\n",
    "    return np.rot90(mask, k=k) if mask is not None else None\n",
    "\n",
    "def flip_mask_horizontal(mask):\n",
    "    \"\"\"마스크를 좌우 뒤집기\"\"\"\n",
    "    return np.fliplr(mask) if mask is not None else None\n",
    "\n",
    "def visualize_augmentation_result(original_image, original_mask, augmented_image, augmented_mask, \n",
    "                                 title=\"Augmentation Result\", save_path=None):\n",
    "    \"\"\"\n",
    "    원본과 증강 결과 시각화\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if original_image is None or augmented_image is None:\n",
    "            print(\"시각화 오류: 이미지가 None입니다.\")\n",
    "            return\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # 원본 이미지와 마스크\n",
    "        ax1.imshow(original_image)\n",
    "        ax1.set_title('원본 이미지')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # 원본 마스크\n",
    "        ax2.imshow(original_mask, cmap='gray')\n",
    "        ax2.set_title('원본 마스크')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # 증강 이미지와 마스크\n",
    "        ax3.imshow(augmented_image)\n",
    "        ax3.set_title('증강 이미지')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        # 증강 마스크\n",
    "        ax4.imshow(augmented_mask, cmap='gray')\n",
    "        ax4.set_title('증강 마스크')\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"시각화 결과 저장: {save_path}\")\n",
    "        else:\n",
    "            plt.show()\n",
    "            \n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"시각화 오류: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "def prepare_dataset(dataset):\n",
    "    \"\"\"\n",
    "    모든 데이터셋 스플릿 준비\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for split in SPLITS:\n",
    "        print(f\"\\n===== {split.upper()} 데이터셋 준비 시작 =====\")\n",
    "        \n",
    "        try:\n",
    "            split_ds = dataset[split]\n",
    "            print(f\"{split} 데이터셋 크기: {len(split_ds)} 이미지\")\n",
    "            \n",
    "            # 준비 작업\n",
    "            for i in tqdm(range(len(split_ds)), desc=f\"{split} 데이터 준비\"):\n",
    "                item = split_ds[i]\n",
    "                \n",
    "                # 필수 데이터 추출\n",
    "                image_np = np.array(item['image'])\n",
    "                \n",
    "                # segmentation이 없거나 비어있으면 건너뛰기\n",
    "                if 'segmentation' not in item or not item['segmentation']:\n",
    "                    print(f\"경고: {split} 항목 {i}에 segmentation이 없습니다.\")\n",
    "                    continue\n",
    "                \n",
    "                # ID 생성\n",
    "                item_id = str(item.get('id', f\"{split}_{i}\"))\n",
    "                \n",
    "                # 원본 파일명 생성\n",
    "                original_filename = f\"original_{item_id}.png\"\n",
    "                \n",
    "                # 마스크 생성 \n",
    "                mask = create_mask_from_polygon(item['segmentation'][0], image_np.shape)\n",
    "                \n",
    "                # 메모리에 저장\n",
    "                all_images[split][original_filename] = {\n",
    "                    'image': image_np,\n",
    "                    'mask': mask\n",
    "                }\n",
    "                \n",
    "                # 메타데이터 생성\n",
    "                meta = {\n",
    "                    'id': item_id,\n",
    "                    'file_name': original_filename,\n",
    "                    'category_id': int(item.get('category_id', 0)),\n",
    "                    'segmentation': item['segmentation'],\n",
    "                    'height': int(image_np.shape[0]),\n",
    "                    'width': int(image_np.shape[1])\n",
    "                }\n",
    "                \n",
    "                # bbox 계산 (마스크 기반)\n",
    "                meta['bbox'] = calculate_bbox_from_mask(mask)\n",
    "                \n",
    "                # area 계산 (마스크 기반)\n",
    "                meta['area'] = calculate_area_from_mask(mask)\n",
    "                \n",
    "                # 추가 메타데이터 복사\n",
    "                for field in ['iscrowd', 'license']:\n",
    "                    if field in item:\n",
    "                        meta[field] = item[field]\n",
    "                \n",
    "                # 어노테이션에 추가\n",
    "                all_annotations[split].append(meta)\n",
    "            \n",
    "            # 결과 저장\n",
    "            results[split] = {\n",
    "                'original_count': len(all_annotations[split])\n",
    "            }\n",
    "            \n",
    "            print(f\"{split} 데이터셋 준비 완료: {results[split]['original_count']} 이미지\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{split} 데이터셋 준비 중 오류 발생: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            results[split] = {'original_count': 0}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def augment_dataset(visualization_path=None):\n",
    "    \"\"\"\n",
    "    모든 데이터셋 스플릿 증강\n",
    "    \"\"\"\n",
    "    # 증강 유형\n",
    "    aug_types = {\n",
    "        '90도_회전': {'image_func': rotate_image_90, 'mask_func': lambda m: rotate_mask_90(m, k=1)},\n",
    "        '180도_회전': {'image_func': rotate_image_180, 'mask_func': lambda m: rotate_mask_90(m, k=2)},\n",
    "        '270도_회전': {'image_func': rotate_image_270, 'mask_func': lambda m: rotate_mask_90(m, k=3)},\n",
    "        '좌우_뒤집기': {'image_func': flip_image_horizontal, 'mask_func': flip_mask_horizontal}\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 시각화 디렉토리 생성\n",
    "    if visualization_path:\n",
    "        os.makedirs(visualization_path, exist_ok=True)\n",
    "    \n",
    "    for split in SPLITS:\n",
    "        print(f\"\\n===== {split.upper()} 데이터셋 증강 시작 =====\")\n",
    "        \n",
    "        try:\n",
    "            original_annotations = all_annotations[split].copy()\n",
    "            augmented_count = 0\n",
    "            \n",
    "            for idx, annotation in enumerate(tqdm(original_annotations, desc=f\"{split} 이미지 증강 중\")):\n",
    "                original_filename = annotation['file_name']\n",
    "                \n",
    "                # 원본 이미지와 마스크 가져오기\n",
    "                if original_filename not in all_images[split]:\n",
    "                    print(f\"경고: {original_filename}을 찾을 수 없습니다.\")\n",
    "                    continue\n",
    "                    \n",
    "                original_data = all_images[split][original_filename]\n",
    "                original_image = original_data['image']\n",
    "                original_mask = original_data['mask']\n",
    "                \n",
    "                # 각 증강 적용\n",
    "                for aug_name, aug_funcs in aug_types.items():\n",
    "                    # 증강 파일명\n",
    "                    augmented_filename = f\"aug_{annotation['id']}_{aug_name}.png\"\n",
    "                    \n",
    "                    # 이미지와 마스크 증강\n",
    "                    augmented_image = aug_funcs['image_func'](original_image)\n",
    "                    augmented_mask = aug_funcs['mask_func'](original_mask)\n",
    "                    \n",
    "                    if augmented_image is None or augmented_mask is None:\n",
    "                        print(f\"경고: {augmented_filename} 증강 실패\")\n",
    "                        continue\n",
    "                    \n",
    "                    # 메모리에 저장\n",
    "                    all_images[split][augmented_filename] = {\n",
    "                        'image': augmented_image,\n",
    "                        'mask': augmented_mask\n",
    "                    }\n",
    "                    \n",
    "                    # bbox 및 area 계산\n",
    "                    augmented_bbox = calculate_bbox_from_mask(augmented_mask)\n",
    "                    augmented_area = calculate_area_from_mask(augmented_mask)\n",
    "                    \n",
    "                    # 어노테이션 생성\n",
    "                    augmented_annotation = annotation.copy()\n",
    "                    augmented_annotation['id'] = f\"{annotation['id']}_aug_{aug_name}\"\n",
    "                    augmented_annotation['file_name'] = augmented_filename\n",
    "                    augmented_annotation['bbox'] = augmented_bbox\n",
    "                    augmented_annotation['area'] = augmented_area\n",
    "                    augmented_annotation['height'] = augmented_image.shape[0]\n",
    "                    augmented_annotation['width'] = augmented_image.shape[1]\n",
    "                    augmented_annotation['augmentation_type'] = aug_name\n",
    "                    \n",
    "                    # segmentation 필드를 마스크로부터 재계산 (중요!)\n",
    "                    # 실제로는 segmentation을 다각형으로 다시 변환해야 하지만,\n",
    "                    # 여기서는 단순화를 위해 원본 segmentation 유지\n",
    "                    \n",
    "                    # 어노테이션 추가\n",
    "                    all_annotations[split].append(augmented_annotation)\n",
    "                    augmented_count += 1\n",
    "                    \n",
    "                    # 첫 5개 이미지에 대해 시각화\n",
    "                    if visualization_path and idx < 5:\n",
    "                        viz_filename = f\"{split}_{annotation['id']}_{aug_name}.png\"\n",
    "                        viz_path = os.path.join(visualization_path, viz_filename)\n",
    "                        visualize_augmentation_result(\n",
    "                            original_image, original_mask, \n",
    "                            augmented_image, augmented_mask,\n",
    "                            title=f\"증강 결과 - {split} - {aug_name}\",\n",
    "                            save_path=viz_path\n",
    "                        )\n",
    "            \n",
    "            # 결과 저장\n",
    "            results[split] = {\n",
    "                'original_count': len(original_annotations),\n",
    "                'augmented_count': augmented_count,\n",
    "                'total_count': len(all_annotations[split])\n",
    "            }\n",
    "            \n",
    "            print(f\"{split} 데이터셋 증강 완료: 원본 {results[split]['original_count']}개, \"\n",
    "                  f\"증강 {results[split]['augmented_count']}개, 총 {results[split]['total_count']}개\")\n",
    "                  \n",
    "        except Exception as e:\n",
    "            print(f\"{split} 데이터셋 증강 중 오류 발생: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            results[split] = {'original_count': 0, 'augmented_count': 0, 'total_count': 0}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_data_to_disk():\n",
    "    \"\"\"\n",
    "    메모리에 있는 모든 데이터를 디스크에 저장\n",
    "    \"\"\"\n",
    "    print(\"\\n===== 모든 데이터를 디스크에 저장 중 =====\")\n",
    "    \n",
    "    success_count = {split: 0 for split in SPLITS}\n",
    "    error_count = {split: 0 for split in SPLITS}\n",
    "    \n",
    "    # 1. 이미지 저장\n",
    "    for split in SPLITS:\n",
    "        print(f\"\\n{split.upper()} 이미지 저장 중...\")\n",
    "        \n",
    "        for filename, data in tqdm(all_images[split].items(), desc=f\"{split} 이미지 저장\"):\n",
    "            try:\n",
    "                # 이미지 경로\n",
    "                image_path = os.path.join(OUTPUT_IMAGES_PATH[split], filename)\n",
    "                \n",
    "                # 이미지 저장 - PIL 사용 (더 안정적)\n",
    "                image_pil = PILImage.fromarray(data['image'])\n",
    "                image_pil.save(image_path, format='PNG')\n",
    "                \n",
    "                # 파일 존재 확인\n",
    "                if os.path.exists(image_path):\n",
    "                    success_count[split] += 1\n",
    "                else:\n",
    "                    print(f\"경고: 이미지 파일이 생성되지 않음 - {image_path}\")\n",
    "                    error_count[split] += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"이미지 저장 오류 ({split}/{filename}): {str(e)}\")\n",
    "                error_count[split] += 1\n",
    "    \n",
    "    # 2. 어노테이션 저장\n",
    "    for split in SPLITS:\n",
    "        try:\n",
    "            annotations_path = OUTPUT_ANNOTATIONS_FILE[split]\n",
    "            with open(annotations_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(all_annotations[split], f, indent=2, ensure_ascii=False)\n",
    "                \n",
    "            print(f\"{split} 어노테이션 저장 완료: {annotations_path} ({len(all_annotations[split])}개)\")\n",
    "        except Exception as e:\n",
    "            print(f\"어노테이션 저장 오류 ({split}): {str(e)}\")\n",
    "    \n",
    "    # 결과 요약\n",
    "    print(\"\\n===== 데이터 저장 결과 =====\")\n",
    "    for split in SPLITS:\n",
    "        print(f\"{split}: 성공 {success_count[split]}개, 오류 {error_count[split]}개\")\n",
    "    \n",
    "    return all([error_count[split] == 0 for split in SPLITS])\n",
    "\n",
    "def create_hf_dataset():\n",
    "    \"\"\"\n",
    "    허깅페이스 데이터셋 생성 및 업로드\n",
    "    \"\"\"\n",
    "    print(\"\\n===== 허깅페이스 데이터셋 생성 중 =====\")\n",
    "    \n",
    "    unified_dataset = {}\n",
    "    \n",
    "    for split in SPLITS:\n",
    "        print(f\"\\n{split.upper()} 데이터셋 처리 중...\")\n",
    "        \n",
    "        try:\n",
    "            # 어노테이션 로드\n",
    "            annotations = all_annotations[split]\n",
    "            \n",
    "            # 데이터 준비\n",
    "            data = {\n",
    "                \"id\": [],\n",
    "                \"file_name\": [],\n",
    "                \"image\": [],\n",
    "                \"category_id\": [],\n",
    "                \"bbox\": [],\n",
    "                \"area\": [],\n",
    "                \"segmentation\": []\n",
    "            }\n",
    "            \n",
    "            # 추가 필드 확인\n",
    "            extra_fields = set()\n",
    "            for ann in annotations[:10]:\n",
    "                for key in ann.keys():\n",
    "                    if key not in data and key not in [\"height\", \"width\"]:\n",
    "                        extra_fields.add(key)\n",
    "                        data[key] = []\n",
    "            \n",
    "            # 데이터 채우기\n",
    "            for idx, ann in enumerate(tqdm(annotations, desc=f\"{split} 데이터셋 생성\")):\n",
    "                try:\n",
    "                    # 필수 필드\n",
    "                    data[\"id\"].append(str(ann[\"id\"]))\n",
    "                    data[\"file_name\"].append(ann[\"file_name\"])\n",
    "                    data[\"category_id\"].append(int(ann[\"category_id\"]))\n",
    "                    data[\"bbox\"].append(ann[\"bbox\"])\n",
    "                    data[\"area\"].append(float(ann[\"area\"]))\n",
    "                    data[\"segmentation\"].append(ann[\"segmentation\"])\n",
    "                    \n",
    "                    # 추가 필드\n",
    "                    for field in extra_fields:\n",
    "                        if field in ann:\n",
    "                            data[field].append(ann[field])\n",
    "                        else:\n",
    "                            data[field].append(\"\")\n",
    "                    \n",
    "                    # 이미지 로드\n",
    "                    image_path = os.path.join(OUTPUT_IMAGES_PATH[split], ann[\"file_name\"])\n",
    "                    if os.path.exists(image_path):\n",
    "                        img = PILImage.open(image_path)\n",
    "                        data[\"image\"].append(img)\n",
    "                    else:\n",
    "                        print(f\"경고: 이미지 파일을 찾을 수 없음 - {image_path}\")\n",
    "                        # 빈 이미지 사용\n",
    "                        data[\"image\"].append(PILImage.new('RGB', (640, 640), color='black'))\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"항목 처리 오류 ({split}/{idx}): {str(e)}\")\n",
    "            \n",
    "            # 스키마 정의\n",
    "            features = Features({\n",
    "                \"id\": Value(\"string\"),\n",
    "                \"file_name\": Value(\"string\"),\n",
    "                \"image\": Image(),\n",
    "                \"category_id\": Value(\"int64\"),\n",
    "                \"bbox\": Sequence(Value(\"float32\")),\n",
    "                \"area\": Value(\"float32\"),\n",
    "                \"segmentation\": Sequence(Sequence(Value(\"float32\")))\n",
    "            })\n",
    "            \n",
    "            # 추가 필드 스키마\n",
    "            for field in extra_fields:\n",
    "                features[field] = Value(\"string\")\n",
    "            \n",
    "            # 데이터셋 생성\n",
    "            unified_dataset[split] = Dataset.from_dict(data, features=features)\n",
    "            print(f\"{split} 데이터셋 생성 완료: {len(unified_dataset[split])} 샘플\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{split} 데이터셋 생성 오류: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # 데이터셋 딕셔너리 생성\n",
    "    try:\n",
    "        if unified_dataset:\n",
    "            dataset_dict = DatasetDict({\n",
    "                split: unified_dataset[split] for split in unified_dataset.keys()\n",
    "            })\n",
    "            \n",
    "            # 허깅페이스에 업로드\n",
    "            print(\"\\n허깅페이스에 데이터셋 업로드 중...\")\n",
    "            dataset_dict.push_to_hub(\n",
    "                \"espada105/augmented-brain-tumor-segmentation-v2\",\n",
    "                private=False\n",
    "            )\n",
    "            print(\"데이터셋 업로드 완료!\")\n",
    "            \n",
    "            # 업로드된 데이터셋 요약\n",
    "            print(\"\\n===== 업로드된 데이터셋 요약 =====\")\n",
    "            for split in unified_dataset:\n",
    "                print(f\"{split}: {len(unified_dataset[split])} 샘플\")\n",
    "            \n",
    "            total_samples = sum([len(unified_dataset[split]) for split in unified_dataset])\n",
    "            print(f\"총 샘플 수: {total_samples}\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"업로드할 데이터셋이 없습니다.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"데이터셋 업로드 오류: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # 1. 디렉토리 설정\n",
    "        if not setup_directories():\n",
    "            print(\"오류: 디렉토리 설정 실패\")\n",
    "            return\n",
    "        \n",
    "        # 2. 허깅페이스 로그인\n",
    "        login(token=HF_TOKEN)\n",
    "        \n",
    "        # 3. 데이터셋 로드\n",
    "        dataset = load_dataset_from_huggingface()\n",
    "        \n",
    "        # 4. 시각화 디렉토리 생성\n",
    "        viz_path = os.path.join(OUTPUT_PATH, \"visualizations\")\n",
    "        os.makedirs(viz_path, exist_ok=True)\n",
    "        \n",
    "        # 5. 데이터셋 준비 (메모리에 로드)\n",
    "        prep_results = prepare_dataset(dataset)\n",
    "        \n",
    "        # 6. 데이터셋 증강 (메모리 내에서)\n",
    "        aug_results = augment_dataset(visualization_path=viz_path)\n",
    "        \n",
    "        # 7. 디스크에 모든 데이터 저장\n",
    "        save_results = save_data_to_disk()\n",
    "        \n",
    "        if not save_results:\n",
    "            print(\"경고: 일부 데이터가 제대로 저장되지 않았습니다.\")\n",
    "        \n",
    "        # 8. 허깅페이스 데이터셋 생성 및 업로드\n",
    "        create_hf_dataset()\n",
    "        \n",
    "        # 9. 처리 시간 계산\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        print(f\"\\n총 처리 시간: {processing_time:.2f}초 ({processing_time/60:.2f}분)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류 발생: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69467c47",
   "metadata": {},
   "source": [
    "# HuggingFace Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets huggingface_hub pillow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
